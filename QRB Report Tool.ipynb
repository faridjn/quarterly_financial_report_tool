{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2PLCIfD8tb0"
   },
   "source": [
    "# QBR Report Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMSgAF7PYuAM"
   },
   "source": [
    "Author: Farid Javadnejad\\\n",
    "Latest Update: 1/13/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPCOkHOnu872"
   },
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ydWZ0j-YoHO",
    "outputId": "2184d6ab-a3e8-4d3d-8aa1-5514477efa73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.0.7-py3-none-any.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.0.7\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy, Pandas, PyPlot SeaBorn libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tick\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Google Colab filer upload libs\n",
    "import io\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "\n",
    "# Import Google Sheet access authentication libs\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "import gspread\n",
    "from google.auth import default\n",
    "creds, _ = default()\n",
    "\n",
    "#Files & folders\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "#time\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "#Excel file handling\n",
    "!pip install xlsxwriter\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djUqWoH02Inu"
   },
   "source": [
    "Global: Colors & Font Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48v-qzkmvV0w"
   },
   "outputs": [],
   "source": [
    "#Define global variables\n",
    "#Colors\n",
    "global COLOR_SET_google\n",
    "COLOR_SET_google = ['#4486F4', '#51B457', '#F3C302', '#E44B31']\n",
    "\n",
    "#Set default font size\n",
    "global FONT_SIZE\n",
    "FONT_SIZE = \"13\"\n",
    "\n",
    "global DIRECTORY\n",
    "\n",
    "global PALLETE\n",
    "PALLETE = ['viridis', 'magma', 'plasma', 'tab20', 'tab10', 'paired']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnH10_bb8-BX"
   },
   "source": [
    "## Custom Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_POi30gWKXUC"
   },
   "source": [
    "### Color Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIQukbC2r3wV"
   },
   "source": [
    "f: Color Picker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gev5vSx8VHPd"
   },
   "outputs": [],
   "source": [
    "def gradient_color_picker(i,n, pallete = 'PALLETE'):\n",
    "\n",
    "    magma = ['#000004', '#120d31', '#331067', '#59157e', '#7e2482', '#a3307e', '#c83e73', '#e95462', '#fa7d5e',' #fea973', '#fed395', '#fcfdbf']\n",
    "\n",
    "    tab20 = ['#1f77b4', '#17becf', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b',\n",
    "           '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d', '#6baed6', '#9edae5']\n",
    "\n",
    "    tab10 = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22','#17becf']\n",
    "\n",
    "    viridis = ['#440154', '#481b6d', '#46327e', '#3f4788', '#365c8d', '#2e6e8e', '#277f8e', '#21918c',\n",
    "             '#1fa187', '#2db27d', '#4ac16d', '#73d056', '#a0da39', '#d0e11c', '#fde725']\n",
    "\n",
    "    plasma = ['#0d0887', '#350498', '#5302a3', '#6f00a8', '#8b0aa5', '#a31e9a', '#b83289', '#cc4778', '#db5c68',\n",
    "          '#e97158', '#f48849', '#fba238', '#febd2a', '#fada24', '#f0f921']\n",
    "\n",
    "    paired =['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c',\n",
    "           '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928']\n",
    "\n",
    "\n",
    "    if pallete == 'viridis':\n",
    "        pallete = viridis\n",
    "    elif pallete == 'plasma':\n",
    "        pallete = plasma\n",
    "    elif pallete == 'tab20':\n",
    "        pallete = tab20\n",
    "    elif pallete == 'tab10':\n",
    "        pallete = tab10\n",
    "    else:\n",
    "        pallete = magma \n",
    "\n",
    "    sizeOfList = len(pallete) - 1\n",
    "    \n",
    "    if n < 0 or n > sizeOfList:\n",
    "        raise ValueError #The accepted values are between 0 - {sizeOfList}\n",
    "\n",
    "    if i > n:\n",
    "        raise ValueError #i can not be larget than {sizeOfList}\n",
    "\n",
    "    idx = sizeOfList*i//n\n",
    "\n",
    "    return pallete[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HXEZb2vKoH0"
   },
   "source": [
    "### Reading Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCQwFZsBmVqI"
   },
   "source": [
    "Generate Keyword from List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdYxkDPumeJE"
   },
   "outputs": [],
   "source": [
    "def keyword_from_list(li: list):\n",
    "    ''' Gets a list of strings and returns one string as keyword'''\n",
    "\n",
    "    str_list = filter(lambda item: item !='', li)  #remove empty items from list\n",
    "    key_words ='|'.join(str_list)  #keyword Generator\n",
    "    return key_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_CKew1smhZ8"
   },
   "source": [
    "Goolge Workbook to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFZmFZMrmftK"
   },
   "outputs": [],
   "source": [
    "def workbook_to_dataframe(work_book, work_sheet):\n",
    "    '''Gets a GoogleSheet workbook and worksheet name oand retrun a dataframe'''\n",
    "\n",
    "    ws = work_book.worksheet(work_sheet) #read the worksheet\n",
    "    rows = ws.get_all_values() #get_all_values gives a list of rows\n",
    "    df = pd.DataFrame.from_records(rows) #create a dataframe from all values\n",
    "    df.replace('', np.nan) #data cleanup\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSz3a37wm3Rn"
   },
   "source": [
    "f: Read GoogleSheet by URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR3kJkekm6vV"
   },
   "outputs": [],
   "source": [
    "def read_gs_by_url(url: str):\n",
    "    ''' Read a workbook by url '''\n",
    "\n",
    "    gc = gspread.authorize(creds)\n",
    "    wb = gc.open_by_url(url)\n",
    "    return wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdSNaglanD1Q"
   },
   "source": [
    "f: Cast df colum to a dictionry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qISc0HJCnDFV"
   },
   "outputs": [],
   "source": [
    "def column_to_dict(column, output = True):\n",
    "    ''' Cast dataframe columnto a dictionry '''  \n",
    "    dct = {}\n",
    "    i = 0\n",
    "    for item in column:\n",
    "    if item != '':    \n",
    "        dct[i]= item\n",
    "        i +=1\n",
    "    if output:\n",
    "    for a,b in dct.items():\n",
    "        print(a, ':', b)\n",
    "    return dct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANZ4iKTiK1xP"
   },
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2DWc9Finiwa"
   },
   "source": [
    "f: Replace df header with 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FUniZNjniPR"
   },
   "outputs": [],
   "source": [
    "def dataframe_header(df: pd.DataFrame):\n",
    "    ''' Python Pandas Replacing Header with Top Row '''\n",
    "    df_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = df_header #set the header row as the df header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyfFYvyGnp5Z"
   },
   "source": [
    "f: Get User Input (Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cClNWJBbnpKv"
   },
   "outputs": [],
   "source": [
    "def get_user_input_int(lower: int, upper: int):\n",
    "    '''User input to select the product'''\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            val = int(input('\\nEnter an integer value: '))\n",
    "            if val < lower or val > upper:\n",
    "                raise ValueError #this will send it to the print message and back to the input option\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(f\"INVALID: The number must be between ({lower} - {upper}).\")\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSSYjaMsLtOu"
   },
   "source": [
    "f: Add Q, Year, m_in_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFSGf6LDLOQ7"
   },
   "outputs": [],
   "source": [
    "def add_q_year_month(df):\n",
    "    #Delete rows without valid 'MM_YY' data\n",
    "    df = df[df['MM_YY'].str.get(0).isin(['0'])==True]\n",
    "\n",
    "    #Define Quarter column\n",
    "    df['Q'] = (df['MM_YY'].str[1:3].astype(float)/3).apply(np.ceil).astype(int)\n",
    "    #Define Year column\n",
    "    df['Year'] = df['MM_YY'].str[-4:].astype(int)\n",
    "    df['m_in_Q'] = (df['MM_YY'].str[1:3].astype(int))-df['Q']*3 + 3\n",
    "\n",
    "    #sort by Year, Q, m_in_Q\n",
    "    df = df.sort_values(by=['Year', 'Q', 'm_in_Q'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsxDR6xen7Qd"
   },
   "source": [
    "f: QTD, PreQTD, LYQTD Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWibtDQcn6Hz"
   },
   "outputs": [],
   "source": [
    "def qtd_encoder(df: pd.DataFrame):\n",
    "    '''This function add QTD, PreQTD, LYQTD Encoding for the sales report dataframe'''\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    #Create a new colum to classify QTD\n",
    "    df_encoded['QTD_Encoding'] = 'O'\n",
    "\n",
    "    #get the current Year, Quarter, and month in Quarter\n",
    "    current_q = df['Q'].iloc[-1]\n",
    "    current_yr = df['Year'].iloc[-1]\n",
    "    current_m_in_Q = df['m_in_Q'].iloc[-1]\n",
    "    print(f'Current qaurter is:\\nQ = {current_q}\\nYear = {current_yr}\\nm_in_Q = {current_m_in_Q}\\n')\n",
    "\n",
    "    #create a filter for current quarter-to-date (QTD)\n",
    "    qtd_filter = (df['Q'] == current_q) & (df['Year'] == current_yr)\n",
    "\n",
    "    ################\n",
    "    #print(qtd_filter[:10])\n",
    "\n",
    "    #create a filter for previous quarter-to-date (PreQTD)\n",
    "    preqtd_filter = (df['Q'] == current_q - 1) & (df['Year'] == current_yr) & (df['m_in_Q'] <= current_m_in_Q)\n",
    "\n",
    "    if current_q == 1:\n",
    "    preqtd_filter = (df['Q'] == 4) & (df['Year'] == (current_yr -1)) & (df['m_in_Q'] <= current_m_in_Q)\n",
    "\n",
    "\n",
    "    ################\n",
    "    #print(preqtd_filter[:10])\n",
    "\n",
    "    #create a filter for last year quarter-to-date (LYQTD)\n",
    "    lyqtd_filter = (df['Q'] == current_q) & (df['Year'] == (current_yr-1)) & (df['m_in_Q'] <= (current_m_in_Q))\n",
    "\n",
    "    ################\n",
    "    #print(lyqtd_filter[:10])\n",
    "\n",
    "    df_encoded.QTD_Encoding[qtd_filter] = 'QTD'\n",
    "    df_encoded.QTD_Encoding[preqtd_filter] = 'PreQTD'\n",
    "    df_encoded.QTD_Encoding[lyqtd_filter] = 'LYQTD'\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54LHVT2HKMvd"
   },
   "source": [
    "### Calculations Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obNGk1ktn58B"
   },
   "source": [
    "f: Calcualte MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKOJPTgXYppA"
   },
   "outputs": [],
   "source": [
    "def calculate_mat(df: pd.DataFrame, product_name:str):\n",
    "    '''This function gets a sales dataframe that includes QTD Encoding and calcuates MAT df '''\n",
    "    #Aggregate Sales & Billing values\n",
    "    group_data = df.groupby(['MM_YY', 'Q','Year', 'm_in_Q', 'QTD_Encoding'],as_index=False)['Sales', 'Billing'].sum()\n",
    "\n",
    "    #sory by Year, Q, month in Q\n",
    "    group_data = group_data.sort_values(by=['Year', 'Q', 'm_in_Q']).reset_index()\n",
    "    group_data['Billing_MAT'] = group_data.Billing.rolling(window=12).sum()\n",
    "    group_data['Sales_MAT'] = group_data.Sales.rolling(window=12).sum()\n",
    "\n",
    "    # 12 month period for MAT\n",
    "    group_data['Start_Period'] = group_data.MM_YY.shift(periods=11)\n",
    "\n",
    "    # Create period labels\n",
    "    group_data['Period'] = group_data['Start_Period'].str[1:] + ' - ' + group_data['MM_YY'].str[1:]\n",
    "\n",
    "    #df_MAT['Period'].astype(str)\n",
    "    group_data['Billing_MAT'].astype(float)\n",
    "    group_data['Sales_MAT'].astype(float)\n",
    "    group_data['YYYYMM'] = group_data['MM_YY'].astype(str).str[4:] + group_data['MM_YY'].astype(str).str[1:3]\n",
    "    group_data['Date'] = pd.to_datetime(group_data['YYYYMM'], format='%Y%m', errors='coerce') + MonthEnd(1)\n",
    "    group_data['Product'] = product_name\n",
    "\n",
    "    #Subset the dataframe\n",
    "    df_MAT = group_data[['Product', 'Date', 'Sales', 'Billing', 'Period', 'Billing_MAT', 'Sales_MAT', 'QTD_Encoding']]\n",
    "\n",
    "    return df_MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NanYDlYYegfz"
   },
   "outputs": [],
   "source": [
    "def calculate_mat_group(df: pd.DataFrame, mat_by = 'MAT_by'):\n",
    "\n",
    "    ### TEST ####\n",
    "    #df = filtered_df\n",
    "    #######################\n",
    "\n",
    "    MAT_by = ['GROUP', 'Region']\n",
    "\n",
    "    df_MAT = calculate_mat(df, 'CD')\n",
    "\n",
    "    all_GROUP = df[mat_by].unique()\n",
    "    #Aggregate Sales & Billing values\n",
    "\n",
    "    for group in all_GROUP:\n",
    "    if group != 0:    \n",
    "        df_GROUP = df[df[mat_by] == group]\n",
    "        df_MAT_GROUP = calculate_mat(df_GROUP, group)  \n",
    "        df_MAT = pd.concat([df_MAT, df_MAT_GROUP], axis=0)\n",
    "\n",
    "    return df_MAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2b1qBSKUJVx"
   },
   "source": [
    "f: Caclulate Quarter Sales Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5imhvgIwUCI1"
   },
   "outputs": [],
   "source": [
    "def generate_q_sales_report(df: pd.DataFrame, product_name:str):\n",
    "    ''' Calculate Quarte Sales Trend report '''\n",
    "\n",
    "    filter_qtd_sales = (df['QTD_Encoding'] == 'QTD')\n",
    "    filter_preqtd_sales = (df['QTD_Encoding'] == 'PreQTD')\n",
    "    filter_lyqtd_sales = (df['QTD_Encoding'] == 'LYQTD')\n",
    "\n",
    "    #Sum of Sales for Quarter to Date (QTD)\n",
    "    QTD = (df[filter_qtd_sales].Sales.sum()).astype(float)\n",
    "\n",
    "    #Sum of Sales for Last Year Quarter to Date (LYQTD)\n",
    "    PreQTD = (df[filter_preqtd_sales].Sales.sum()).astype(float)\n",
    "\n",
    "    #Sum of Sales for Last Year Quarter to Date (LYQTD)\n",
    "    LYQTD = (df[filter_lyqtd_sales].Sales.sum()).astype(float)\n",
    "\n",
    "    #  data of lists.\n",
    "    q_report_data = {'Product':[product_name],\n",
    "      'QTD(kEUR)':[QTD/1000],  #convert to kEUR\n",
    "      'PreQTD(kEUR)':[PreQTD/1000], #convert to kEUR\n",
    "      'LYQTD(kEUR)':[LYQTD/1000], #convert to kEUR\n",
    "      'Rel_PreQTD(%)':[(100*QTD/PreQTD).astype(int)], #convert to %\n",
    "      'Rel_LYQTD(%)':[(100*QTD/LYQTD).astype(int)] #convert to % \n",
    "      }\n",
    "\n",
    "    # Create Q Report DataFrame\n",
    "    q_report_df = pd.DataFrame(q_report_data)\n",
    "    q_report_df = q_report_df.round({'QTD(kEUR)':1, 'PreQTD(kEUR)':1, 'LYQTD(kEUR)':1, 'Rel_PreQTD(%)':0,'Rel_LYQTD(%)':0} )\n",
    "\n",
    "    return q_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEoph-o2NomQ"
   },
   "source": [
    "f: Clean-up & Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vNWJBVCNZ4X"
   },
   "outputs": [],
   "source": [
    "def cleanup_and_rename(df):\n",
    "    #Set the Headers\n",
    "    column_header =['PID', 'License', 'Region_ID', 'Region', 'MM_YY', 'Billing', 'Qty', 'Sales']\n",
    "    df.columns = column_header\n",
    "\n",
    "\n",
    "    #Filter world cummulative sales values and keep regions \n",
    "    world_sales_filter = df['Region'].str.contains(\"World GEO|Sales Reg HGS\").fillna(False)\n",
    "    df = df[~world_sales_filter.values]\n",
    "\n",
    "    #Clean up Region name\n",
    "    df['Region'] = df['Region'].str.replace('GSR', '')\n",
    "\n",
    "    #Rename Region Names:\n",
    "    df['Region'] = df['Region'].str.replace('US/CAN', 'US/CA')\n",
    "    df['Region'] = df['Region'].str.replace('Europe', 'EU')\n",
    "    df['Region'] = df['Region'].str.replace('Emerging', 'EM')\n",
    "\n",
    "\n",
    "    #Delete rows without valid 'MM_YY' data\n",
    "    df = df[df['MM_YY'].str.get(0).isin(['0'])==True]\n",
    "    #fill NaN with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    #Convert to numeric values\n",
    "    df['Billing'] = (df['Billing']).astype(float)\n",
    "    df['Sales'] = (df['Sales']).astype(float)\n",
    "    df['Qty'] = (df['Qty']).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoclKoGEo9YR"
   },
   "source": [
    "f: Calculate QTD sales by License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KewVqy-Z8oS"
   },
   "outputs": [],
   "source": [
    "def generate_qtd_sales_by_license(df:pd.DataFrame, product_name: str):\n",
    "\n",
    "    #limit the data for QTD sales\n",
    "    by_license_filter = df['QTD_Encoding'] == 'QTD'\n",
    "    df_qtd = df[by_license_filter]\n",
    "\n",
    "    #Filters\n",
    "    filter_permanent = df['EID_CODE'].str.contains('PERM')\n",
    "    filter_subscription = df['EID_CODE'].str.contains('SUB')\n",
    "    filter_ccp = df['EID_CODE'].str.contains('CCP')\n",
    "    filter_support = df['EID_CODE'].str.contains('SUPPORT')\n",
    "    filter_prorated = df['EID_CODE'].str.contains('PRO-RATED')\n",
    "    filter_updates = df['EID_CODE'].str.contains('UPDATE')\n",
    "    filter_other = df['EID_CODE'].str.contains('OTHER')\n",
    "\n",
    "    #Apply filters\n",
    "    permanent_sales = df_qtd.Sales[filter_permanent].sum()\n",
    "    permanent_qty = df_qtd.Qty[filter_permanent].sum()\n",
    "\n",
    "    subscription_sales = df_qtd.Sales[filter_subscription].sum() + df_qtd.Sales[filter_prorated].sum()\n",
    "    subscription_qty = df_qtd.Qty[filter_subscription].sum() #Don't include pro-rated qty (unit in weeks)\n",
    "\n",
    "    ccp_sales = (df_qtd.Sales[filter_ccp].sum() + df_qtd.Sales[filter_support].sum() + df_qtd.Sales[filter_updates].sum())\n",
    "    qty_ccp = df_qtd.Qty[filter_ccp].sum() + (df_qtd.Qty[filter_support].sum() + df_qtd.Qty[filter_updates].sum())/2\n",
    "\n",
    "    other_sales = df_qtd.Sales[filter_other].sum()\n",
    "    other_qty = df_qtd.Qty[filter_other].sum()\n",
    "\n",
    "\n",
    "    #  data of lists; convert to kEUR\n",
    "    by_license_data = {'Product':[product_name, product_name],\n",
    "          'Unit':['Sales (kEUR)', 'Seat (Qty)'],\n",
    "          'Perpetual':[0.001*permanent_sales, permanent_qty],\n",
    "          'Subscription':[0.001*subscription_sales, subscription_qty],\n",
    "          'CCP':[0.001*ccp_sales, qty_ccp],\n",
    "          'Other':[0.001*other_sales, other_qty]}\n",
    "\n",
    "    by_license_df = pd.DataFrame(by_license_data)\n",
    "    by_license_df.round(1)\n",
    "\n",
    "    return by_license_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XcrOH7x7HOp"
   },
   "source": [
    "f: Add missing regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HywchjJh6n1x"
   },
   "outputs": [],
   "source": [
    "def add_missing_regions(df):\n",
    "\n",
    "    #create a list of all Regions\n",
    "    list_all_regions = ['LATAM', 'EM EMEA', 'India', 'Nordics', 'Russia', 'ANZ', 'China', 'Asia', 'UK/BX', 'Central EU','South EU','US/CA']\n",
    "\n",
    "    #create an empty DataFrame\n",
    "    df_all_regions = pd.DataFrame(data=None, columns = df.columns)\n",
    "\n",
    "    #add all region with 0 sales value to make sure all regions are shown in the plot\n",
    "    for region in list_all_regions:\n",
    "    if ~df['Region'].str.contains(region).any():\n",
    "        region_dict = {'Region': region, 'MM_YY': '00', 'Sales': 0, 'EID_CODE': 'PERM', 'QTD_Encoding': 'QTD'}\n",
    "        temporary_df = pd.DataFrame.from_dict([region_dict])\n",
    "        df_all_regions = df_all_regions.append(temporary_df, ignore_index=True)\n",
    "\n",
    "    #concat the df_region and df_all_regions \n",
    "    df_region_concat = pd.concat([df, df_all_regions], ignore_index=True)\n",
    "\n",
    "    return df_region_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M88vsN1n15ux"
   },
   "source": [
    "f: Add missing periods to MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBAZgmq32BJr"
   },
   "outputs": [],
   "source": [
    "def add_missing_month_MAT(df_new, df_ref):\n",
    "  ######### TEST ########\n",
    "    '''\n",
    "    df_ref = temp_data_0\n",
    "    df_new = df_MAT_new\n",
    "    '''\n",
    "    ########################\n",
    "\n",
    "    df_merged = pd.merge(df_ref, df_new, suffixes = ('_ref', '_new'), on='Date')   \n",
    "\n",
    "    #create an empty DataFrame\n",
    "    df_all_new = pd.DataFrame(data=None, columns = df_ref.columns)\n",
    "\n",
    "\n",
    "    df_all_new['Date'] = df_merged['Date']\n",
    "    df_all_new['Sales'] = df_merged['Sales_new']\n",
    "    df_all_new['Billing'] = df_merged['Billing_new']\n",
    "    df_all_new['Period'] = df_merged['Period_ref']\n",
    "    df_all_new['Billing_MAT'] = df_merged['Billing_MAT_new']\n",
    "    df_all_new['Sales_MAT'] = df_merged['Sales_MAT_new']\n",
    "    df_all_new['QTD_Encoding'] = df_merged['QTD_Encoding_new']\n",
    "    df_all_new.loc[:,'Product'] = list(df_merged['Product_new'])[-1]\n",
    "\n",
    "    #print(df_all_new.tail(3))\n",
    "\n",
    "    return df_all_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWdueq1xS7p4"
   },
   "source": [
    "f: Calculate Sales by Region & Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxNdD_gV4XeW"
   },
   "outputs": [],
   "source": [
    "def calculate_sales_by_region_and_quarter(df:pd.DataFrame, product_name: str): \n",
    "\n",
    "    #filter to the QTD, PreQTD, LYQTD\n",
    "    df_region = df[df['QTD_Encoding'] != 'O']\n",
    "\n",
    "    #add missing regions\n",
    "    df_all_regions = add_missing_regions(df_region)\n",
    "\n",
    "    #Aggregate based on QTD Encoding\n",
    "    df_region_agg = df_all_regions.groupby(['Region', 'QTD_Encoding'])['Sales'].agg('sum').reset_index()\n",
    "\n",
    "    #sort by Sales\n",
    "    df_region_agg = df_region_agg.sort_values(['Region', 'QTD_Encoding', 'Sales'], ascending= True)\n",
    "    df_region_agg = df_region_agg[df_region_agg[\"Region\"] != 0]\n",
    "\n",
    "    df_region_agg.insert(0,'Product', product_name)\n",
    "\n",
    "    return df_region_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7blO9945TR3i"
   },
   "source": [
    "f: Calculate Sales by Region & Lic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfAMqr3bTawt"
   },
   "outputs": [],
   "source": [
    "def calculate_sales_by_region_and_lic(df:pd.DataFrame, product_name: str): \n",
    "\n",
    "    #filter to the QTD, PreQTD, LYQTD\n",
    "    df_region = df[df['QTD_Encoding'] == 'QTD']\n",
    "\n",
    "    #add missing regions\n",
    "    df_all_regions = add_missing_regions(df_region)\n",
    "\n",
    "    #Aggregate based on 'EID_CODE'\n",
    "    df_region_agg = df_all_regions.groupby(['Region', 'EID_GROUP'])['Sales'].agg('sum').reset_index()\n",
    "\n",
    "    #sort by Sales\n",
    "    df_region_agg = df_region_agg.sort_values(['Region', 'EID_GROUP', 'Sales'], ascending= True)\n",
    "    df_region_agg.drop(df_region_agg[df_region_agg['Region'] == 0].index, inplace = True)\n",
    "\n",
    "    #drop MISC & OTHER license types\n",
    "    df_region_agg = df_region_agg[~df_region_agg['EID_GROUP'].str.contains('Miscsallanous')]\n",
    "\n",
    "    df_region_agg.insert(0,'Product', product_name)\n",
    "\n",
    "    return df_region_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCHN5gIALJ6Z"
   },
   "source": [
    "### Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tvFiWq6LJuI"
   },
   "source": [
    "f: Plot QTD Sales by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLx4sc8mgzLd"
   },
   "outputs": [],
   "source": [
    "def plot_qtd_sales_region (df:pd.DataFrame, dir:str, product_name:str, display = True, pallete = 'PALLETE'):\n",
    "  \n",
    "    #### TEST\n",
    "\n",
    "    dir = DIRECTORY \n",
    "    #df = temp_data_1\n",
    "    #display = True\n",
    "    #pallete = 'tab20'\n",
    "\n",
    "\n",
    "    product_name = PRODUCT_GROUP\n",
    "\n",
    "    plot_df = df[df[\"QTD_Encoding\"] == 'QTD']\n",
    "    plot_df.sort_values('Sales', ascending = False, inplace = True)\n",
    "\n",
    "    #calucalte totale sales\n",
    "    total_sales = plot_df['Sales'].sum()\n",
    "\n",
    "    #calculte pecentage\n",
    "    plot_df['Sales'] = 100*plot_df['Sales']/total_sales\n",
    "\n",
    "    ### SETTINGS\n",
    "\n",
    "    #Turn interactive plotting off\n",
    "    if not display:\n",
    "    plt.ioff()\n",
    "\n",
    "    #plot & font size\n",
    "    plt.figure(figsize=[11,7])\n",
    "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
    "\n",
    "\n",
    "    #### DATA ###\n",
    "    #get Sales row of the dataframe\n",
    "\n",
    "    #plot values\n",
    "    plot_labels = list(plot_df['Region']) \n",
    "    plot_sizes = list(plot_df['Sales'])\n",
    "    pie_plot_labels = [f'{l}: {s:0.1f}%' for l, s in zip(plot_labels, plot_sizes)]  \n",
    "\n",
    "    #### PLOT ####\n",
    "    #Title\n",
    "    plot_title_by_region = str(product_name) +' - QTD Sales by Region'\n",
    "\n",
    "    #labels\n",
    "    plt.title(plot_title_by_region)\n",
    "\n",
    "    numOfItemx = len(pie_plot_labels)\n",
    "    #explosion\n",
    "\n",
    "    color = []\n",
    "    for i in range(numOfItemx):\n",
    "        color.append(gradient_color_picker(i,numOfItemx, pallete ))\n",
    "    #color = color.append(gradient_color_picker(i,numOfItemx, pallete))\n",
    "\n",
    "    #pie plotdifinition\n",
    "    plt.pie(plot_sizes, colors = color,startangle=90)\n",
    "    plt.legend(pie_plot_labels, bbox_to_anchor=(.95,0.5), loc=\"center right\", bbox_transform=plt.gcf().transFigure)\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    #### STORE ####\n",
    "    #Save as png\n",
    "    file_address = dir + plot_title_by_region\n",
    "    plt.savefig(file_address, bbox_inches = 'tight')\n",
    "\n",
    "    if not display:\n",
    "    plt.close(fig)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38tvMo2t1qrq"
   },
   "source": [
    "f: Plot (Pie): Q Sales by License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSfBgnNdsDvI"
   },
   "outputs": [],
   "source": [
    "def plot_qtd_sales_license (df:pd.DataFrame, dir:str, product_name:str, display = True):\n",
    "    #### TEST\n",
    "    '''\n",
    "    df = qtd_sales_license_seat\n",
    "    dir = DIRECTORY\n",
    "    display = True\n",
    "    product_name = 'ddsdsdsd'\n",
    "    '''\n",
    "    ### SETTINGS\n",
    "    #set color\n",
    "    colors = COLOR_SET_google\n",
    "\n",
    "    #Wedge \n",
    "    wedgeprops  = {\"edgecolor\":\"k\",'linewidth': 0.1, 'linestyle': '-'}\n",
    "\n",
    "    #Turn interactive plotting off\n",
    "    if not display:\n",
    "    plt.ioff()\n",
    "\n",
    "    #plot & font size\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
    "\n",
    "\n",
    "    #### DATA ###\n",
    "    #get Sales row of the dataframe\n",
    "    df_plot = df.drop(columns = ['Product', 'Unit']).sort_index(axis = 1)\n",
    "    df_plot = df_plot.iloc[0]\n",
    "\n",
    "\n",
    "    #plot values\n",
    "    pie_plot_labels = list(df_plot.keys())  #[Perpetual, Subscription, CCP, Other]\n",
    "    pie_plot_x = list(df_plot)\n",
    "\n",
    "    #### PLOT ####\n",
    "    #Title\n",
    "    by_license_plot_title = product_name +' - QTD Sales by License'\n",
    "\n",
    "    #labels\n",
    "    plt.legend(pie_plot_labels, loc=\"upper right\")\n",
    "    plt.title(by_license_plot_title)\n",
    "\n",
    "    #explosion\n",
    "    explode = (0.05, 0.05, 0.05,0.05)\n",
    "\n",
    "    #pie plotdifinition\n",
    "    plt.pie(pie_plot_x, colors = colors, labels=pie_plot_labels, autopct='%1.1f%%', startangle=90, pctdistance=0.85, wedgeprops = wedgeprops, explode = explode)\n",
    "\n",
    "    #draw white circle\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #### STORE ####\n",
    "    #Save as png\n",
    "    plt.savefig(dir + '/' + by_license_plot_title, bbox_inches = 'tight')\n",
    "\n",
    "    if not display:\n",
    "        plt.close(fig)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Um36a0mrKWR"
   },
   "source": [
    "f: Plot (Bar): Sales Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L-1VUXwMlEZ"
   },
   "outputs": [],
   "source": [
    "def plot_q_sales_trend (df:pd.DataFrame, dir, product_name:str, display = True):\n",
    "    ######## TEST ########\n",
    "    '''\n",
    "    df = q_report_df\n",
    "    display = True\n",
    "    dir = DIRECTORY\n",
    "    product_name = 'SSSTHHHHH'\n",
    "    '''\n",
    "    #####################\n",
    "\n",
    "    # Turn interactive plotting off\n",
    "    if not display:\n",
    "        plt.ioff()\n",
    "    \n",
    "\n",
    "    #Transform the data\n",
    "    df = df.rename(columns={'QTD(kEUR)': 'QTD', 'PreQTD(kEUR)': 'PreQTD', 'LYQTD(kEUR)': 'LYQTD'})\n",
    "    df = df.drop(['Rel_PreQTD(%)', 'Rel_LYQTD(%)'], axis = 1)\n",
    "\n",
    "    plot_df = pd.melt(df, id_vars=['Product'], value_vars=['QTD', 'PreQTD', 'LYQTD'], var_name='QTD_Encoding', value_name='Sales')\n",
    "    plot_df['Sales'] = plot_df['Sales']*1000\n",
    "\n",
    "    hue_order = ['LYQTD', 'PreQTD', 'QTD']\n",
    "\n",
    "    #set the lenth of figure based on the number of products\n",
    "    num_of_products = len(plot_df['Product'].unique())\n",
    "    fig_len = 1 + num_of_products * 2 \n",
    "\n",
    "    #agg_function options\n",
    "    add_plot_title_phrase = ' and Quarter'    \n",
    "    sns_colour = sns.set_palette(COLOR_SET_google)\n",
    "    linewidth = 0.4\n",
    "    saturation= 0.9\n",
    "\n",
    "\n",
    "    #plot & font size\n",
    "    plt.figure(figsize=[fig_len,6])\n",
    "    plt.rcParams[\"font.size\"] = FONT_SIZE \n",
    "\n",
    "    #barchart definition\n",
    "    ax = sns.barplot(x='Product', y='Sales', hue= 'QTD_Encoding',\n",
    "                   saturation = saturation,  palette=sns_colour,\n",
    "                   edgecolor = 'black', linewidth = linewidth,\n",
    "                   hue_order = hue_order,\n",
    "                   ci = None, data = plot_df)\n",
    "\n",
    "    #invert x axis to show larget sales at the left\n",
    "    #ax.invert_xaxis()\n",
    "\n",
    "    #Title\n",
    "    plot_title = product_name +'- Quarter Short Term Trends'\n",
    "\n",
    "    #set labels\n",
    "    plt.ylabel(\"Sales (EUR)\")\n",
    "    plt.title(plot_title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0, ha='right')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    #set graphics\n",
    "    plt.grid(linestyle='--', axis='y')\n",
    "\n",
    "    #adding commas to thousands, matplotlib, python\n",
    "    ax.get_yaxis().set_major_formatter(tick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "    #Save & show\n",
    "    plt.savefig(dir + '/' +  plot_title, bbox_inches = 'tight')\n",
    "\n",
    "    if not display:\n",
    "    plt.close()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSH-pRj5WU8a"
   },
   "source": [
    "f: Plot (Bar): Sales by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2trnpyuxWZuL"
   },
   "outputs": [],
   "source": [
    "def plot_sales_by_region(df:pd.DataFrame, product_name: str, dir: str, display = True, agg_function = 'by_columns'):\n",
    "  \n",
    "    ####### TEST ###########\n",
    "    #df = temp_data_1\n",
    "    #product_name = PRODUCT_GROUP\n",
    "    #dir = DIRECTORY\n",
    "    #display = True\n",
    "    #agg_function = 'QTD_Encoding'\n",
    "    #########################\n",
    "\n",
    "\n",
    "\n",
    "    # Turn interactive plotting off\n",
    "    if not display:\n",
    "    plt.ioff()\n",
    "\n",
    "    #agg_function options\n",
    "    by_columns = ['QTD_Encoding', 'EID_GROUP']\n",
    "\n",
    "    if agg_function == by_columns[0]: #when QTD is selected\n",
    "    add_plot_title_phrase = ' and Quarter'    \n",
    "    sns_colour = sns.set_palette(COLOR_SET_google)\n",
    "    linewidth = 0.4\n",
    "\n",
    "    else: # when EID_CODE is selected\n",
    "        add_plot_title_phrase = ' and License'\n",
    "        sns_colour = sns.color_palette(COLOR_SET_google)\n",
    "        linewidth = 0.2\n",
    "\n",
    "    #plot & font size\n",
    "    plt.figure(figsize=[20,6])\n",
    "    plt.rcParams[\"font.size\"] = FONT_SIZE \n",
    "\n",
    "    #barchart definition\n",
    "    ax = sns.barplot(x='Region', y='Sales', hue= agg_function,\n",
    "                   saturation=0.9,  palette=sns_colour, edgecolor = 'black',\n",
    "                   linewidth = linewidth, ci = None, data = df)\n",
    "\n",
    "    #Title\n",
    "    by_region_plot_title = product_name +' - Sales by Region' + add_plot_title_phrase\n",
    "\n",
    "    #set labels\n",
    "    plt.ylabel(\"Sales (EUR)\")\n",
    "    plt.title(by_region_plot_title)\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    plt.yticks(rotation=0, ha='right')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    #set graphics\n",
    "    plt.grid(linestyle='--', axis='y')\n",
    "\n",
    "    #adding commas to thousands, matplotlib, python\n",
    "    ax.get_yaxis().set_major_formatter(tick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "    #Save & show\n",
    "    plt.savefig(dir + '/' +  by_region_plot_title, bbox_inches = 'tight')\n",
    "\n",
    "    if not display:\n",
    "    plt.close()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_UDkgOU93Fg"
   },
   "source": [
    "f: Plot (Line): MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9l6sZtt9Dt82"
   },
   "outputs": [],
   "source": [
    "def plot_MAT(df:pd.DataFrame, product_name:str, dir:str, display=True, startIndex = 0, pallete = 'PALLETE'):\n",
    "    ### TEST ###\n",
    "    '''\n",
    "    df = df_MAT\n",
    "    display = True\n",
    "    dir = DIRECTORY\n",
    "    startIndex = 0\n",
    "    product_name = 'XXXXXX'\n",
    "    pallete = 'viridis'\n",
    "    '''\n",
    "    ########################\n",
    "\n",
    "    # Turn interactive plotting off\n",
    "    if not display:\n",
    "    plt.ioff()\n",
    "    #Get all the products in the df\n",
    "    my_products = df['Product'].unique()\n",
    "    #Use the first product (Product Group)\n",
    "    plot_df = df.loc[df.Product == my_products[startIndex]]\n",
    "\n",
    "    #plot & font size\n",
    "    fig, ax = plt.subplots(figsize=[15,6])\n",
    "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
    "\n",
    "    #plot title\n",
    "    plot_title_mat = product_name +' - Worldwide MAT'\n",
    "\n",
    "\n",
    "    #y and y axes ranges\n",
    "    y_max = 1.1 * max (plot_df['Billing_MAT'].max(),plot_df['Sales_MAT'].max())\n",
    "    x_max = plot_df['Billing_MAT'].count()\n",
    "\n",
    "    #Plot grid, title, and labels\n",
    "    plt.ylabel('EUR')\n",
    "    plt.ylim(0,y_max)\n",
    "    plt.xlim(1,x_max)\n",
    "    plt.title(plot_title_mat)\n",
    "\n",
    "\n",
    "    #Add ticks\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0, ha='right')\n",
    "\n",
    "    #Set grid\n",
    "    plt.grid(linestyle='dotted', axis='y')\n",
    "    plt.grid(linestyle='dotted', axis='x')\n",
    "\n",
    "    #Add thousands comma\n",
    "    current_values = plt.gca().get_yticks()\n",
    "    plt.gca().set_yticklabels(['{:,.0f}'.format(x) for x in current_values])\n",
    "\n",
    "\n",
    "    flag = False\n",
    "    i = 0\n",
    "    for item in my_products[startIndex:]:\n",
    "    #print(item)\n",
    "    plot_df = df.loc[df.Product == item]\n",
    "    x = plot_df['Period'].tolist()\n",
    "\n",
    "    if i == 0 and startIndex == 0:\n",
    "        new_color = gradient_color_picker(i,len(my_products), pallete)\n",
    "        label = str(item) + ': Billing_MAT'\n",
    "        ax.plot(x, plot_df['Billing_MAT'], color = new_color,  label= label)\n",
    "\n",
    "    i = i + 1\n",
    "    new_color = gradient_color_picker(i,len(my_products), pallete)\n",
    "    label = str(item) +': Sales_MAT'\n",
    "    ax.plot(x, plot_df['Sales_MAT'], color = new_color, label= label)\n",
    "\n",
    "    #Add legend\n",
    "    legend = ax.legend(loc='upper left', fontsize='x-small')\n",
    "\n",
    "    #### STORE ####\n",
    "    #Save as png\n",
    "    plt.savefig(dir + '/' + plot_title_mat, bbox_inches = 'tight')\n",
    "\n",
    "    if not display:\n",
    "    plt.close()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNWtQIEkLjIh"
   },
   "source": [
    "### Reshape Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJiMq5_iLrKs"
   },
   "outputs": [],
   "source": [
    "## reshape MAT data for Excel\n",
    "def reshape_excel_plot_MAT(df_MAT):\n",
    "    ''' This funciton gets the MAT WW dataframe and reshapes it for Excel '''\n",
    "    column_names = df_MAT['Product'].unique()\n",
    "\n",
    "    df_plot_temp = df_MAT.loc[df_MAT['Product'] == column_names[0]]\n",
    "    df_MAT_Excel_Plot = df_plot_temp[['Date', 'Period', 'Billing_MAT']]\n",
    "    df_MAT_Excel_Plot.rename(columns = {'Billing_MAT': str(column_names[0]) + ': Billing_MAT'}, inplace = True )\n",
    "\n",
    "    for item in column_names:\n",
    "    df_plot_temp = df_MAT.loc[df_MAT['Product'] == item]\n",
    "    df_plot_temp = df_plot_temp[['Date', 'Sales_MAT']]\n",
    "    df_plot_temp.rename(columns = {'Sales_MAT': (str(item) + ': Sales_MAT')}, inplace = True )\n",
    "    df_MAT_Excel_Plot = df_MAT_Excel_Plot.merge(df_plot_temp, on = 'Date')\n",
    "    df_MAT_Excel_Plot.set_index('Date', inplace = True)\n",
    "\n",
    "\n",
    "    #set \"Period as index\"\n",
    "    df_MAT_Excel_Plot = df_MAT_Excel_Plot.loc[~df_MAT_Excel_Plot['Period'].isnull()]\n",
    "    df_MAT_Excel_Plot.set_index('Period', inplace = True)\n",
    "\n",
    "    return df_MAT_Excel_Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QcSZ5VWL3Lo"
   },
   "outputs": [],
   "source": [
    "## Reshape sales by resgion for Excel\n",
    "def reshape_sales_by_region(sales_by_region_and_lic):\n",
    "    '''This function gets the sales_by_region_and_lic and reshape it to make Excel plot ready'''\n",
    "\n",
    "    region_names = sales_by_region_and_lic['Region'].unique()\n",
    "    df_Excel = pd.DataFrame(index=region_names)\n",
    "\n",
    "    #get the name of all products\n",
    "    names = sales_by_region_and_lic['Product'].unique()\n",
    "\n",
    "    for item in names:\n",
    "    #filter to the first product\n",
    "    df_temp = sales_by_region_and_lic.loc[sales_by_region_and_lic['Product'] == item]\n",
    "    df_temp = df_temp.groupby(by = ['Region'])['Sales'].agg(['sum'])\n",
    "    df_temp.sort_values('sum', ascending = False, inplace = True)\n",
    "\n",
    "    df_temp.rename(columns = {'sum': str(item)}, inplace = True )\n",
    "    df_Excel = pd.merge(df_Excel, df_temp, left_index = True, right_index = True)\n",
    "\n",
    "    df_Excel.sort_values(by = df_Excel.columns[0], ascending = False, inplace = True)\n",
    "\n",
    "    return df_Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GUplF1eWHIj"
   },
   "source": [
    "## --- Data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edwtf1fhupiz"
   },
   "source": [
    "Upload Datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "AeeQ5qkwuvWO",
    "outputId": "e1841b21-5697-4456-9c0f-74c352a3b5a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-d831182a-be84-4a8c-a1ed-74f006158cd8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-d831182a-be84-4a8c-a1ed-74f006158cd8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0b7b4f84183a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Upload -byarticle-byregion Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    151\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Upload -byarticle-byregion Excel file\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcBVJyL0uozs"
   },
   "outputs": [],
   "source": [
    "filename = next(iter(uploaded)) #get the uploaded file\n",
    "df_uploaded = pd.read_excel(io.BytesIO(uploaded[filename])) #cast the excel file to a DataFrame\n",
    "df_uploaded = df_uploaded[1:] #drop the 1st row\n",
    "print(f'The uploaded Excel file has the size of {df_uploaded.shape}\\n')\n",
    "df_uploaded.head() #print first 5 rows of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViixYdppvnfI"
   },
   "source": [
    "⚠️ **IMPORTANT:** Make sure the column names and data math; otherwise, the data should be re-exported or the **Pre-processing: Renaming & Cleaning** section should be modified.\n",
    "```\n",
    "Unnamed: 0 = Article Number\n",
    "Unnamed: 1 = License Name\n",
    "Unnamed: 2 = Region Code\n",
    "Unnamed: 3 = Region Name\n",
    "Unnamed: 4 = Fiscal year/period\t\n",
    "4.2:Billing exFr GC\n",
    "4.4 Billing qty\n",
    "5.2:Sales exFr GC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpkW9TsOWE19"
   },
   "source": [
    "Renaming & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFrt_BpYU7Jf"
   },
   "outputs": [],
   "source": [
    "#Make a copy of df_uploaded\n",
    "df = cleanup_and_rename(df_uploaded)\n",
    "#see the header\n",
    "print(f'The size of dataframe is {df.shape}\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsq-Fg-Kh8Nf"
   },
   "source": [
    "Read product license info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pp7H611GYutQ"
   },
   "outputs": [],
   "source": [
    "#url address for gs workbook\n",
    "workbook_url = 'https://docs.google.com/spreadsheets/d/1Gbwg4edyMHps1QQQmm_6AiR8IDUN0A_6kEtZ0pOWXz8/edit#gid=1839828940'\n",
    "\n",
    "#Read product categories and names inot a DataFrame\n",
    "product_wb = read_gs_by_url(workbook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dj3gKhBrZXt9"
   },
   "outputs": [],
   "source": [
    "#Read dataframes from gs workbook & and clean up the dataframes\n",
    "df_all_lic = workbook_to_dataframe(product_wb, 'All_Licenses')\n",
    "df_product_groups = workbook_to_dataframe(product_wb, 'Product_Groups')\n",
    "\n",
    "df_all_lic = dataframe_header(df_all_lic)\n",
    "df_product_groups = dataframe_header(df_product_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu05h3Hy8b-k"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-G78Vw5uaWO"
   },
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KnFRdHVuZ5B"
   },
   "outputs": [],
   "source": [
    "print(f'The size of dataframe is {df_all_lic.shape}\\n')\n",
    "df_all_lic = df_all_lic.drop_duplicates(subset='PID', keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exj2NtiVu9qz"
   },
   "source": [
    "Merge product & sales dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-uQlnlyu8vc"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_all_lic, on = 'PID', how = 'left')\n",
    "merged_df = merged_df.drop('LICENSE', axis =1 )\n",
    "merged_df = merged_df.drop('Region_ID', axis =1)\n",
    "merged_df = merged_df[merged_df.Region != 0]\n",
    "print(f'The size of dataframe is {merged_df.shape}\\n')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKL8iP3bXlMW"
   },
   "source": [
    "Add Q, year, & month info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mv7SwXYIXkh5"
   },
   "outputs": [],
   "source": [
    "#Add Q, Year, m_in_Q information to df\n",
    "df_q_year_m = add_q_year_month(merged_df)\n",
    "df_q_year_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7q9D3N-qXTX"
   },
   "source": [
    " QTD Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LucZCZ8yl1kw"
   },
   "outputs": [],
   "source": [
    "#Add QTD encoding column to the dataframe\n",
    "df_encoded = qtd_encoder(df_q_year_m)\n",
    "print(f'The size of encoded dataframe is {df_encoded.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K919FlvkiEYq"
   },
   "source": [
    "## --- Select Product ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wKGN3uuggi1"
   },
   "source": [
    "User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB82IXRDZNXB"
   },
   "outputs": [],
   "source": [
    "#Get user user input \n",
    "group_dict = column_to_dict(df_product_groups.columns)\n",
    "productIdx = get_user_input_int(0, len(group_dict)-1)\n",
    "\n",
    "PRODUCT_GROUP = group_dict[productIdx]\n",
    "group_dct = column_to_dict(df_product_groups[PRODUCT_GROUP], output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XR4lwI1OGjv"
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqWuKPP9wsiP"
   },
   "outputs": [],
   "source": [
    "#Processing message\n",
    "print(f'Processing Product Group: {productIdx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RpoGjFVfQEZ"
   },
   "source": [
    "Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ0QnS1F5t9o"
   },
   "outputs": [],
   "source": [
    "#Set working directory\n",
    "DIRECTORY = '/content/QBR_REPORTS/'+ PRODUCT_GROUP + '/'\n",
    "#create directory\n",
    "if os.path.exists(DIRECTORY):\n",
    "    shutil.rmtree(DIRECTORY)\n",
    "os.makedirs(DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUsUIxnCfSpB"
   },
   "source": [
    "Total: All Product in Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdGRW-7v_de1"
   },
   "outputs": [],
   "source": [
    "#========== Filter_ALL: by Articles =========#\n",
    "#filter dataframe with boolean filter\n",
    "boolean_filter_pid = df_encoded[\"CD\"].str.contains(PRODUCT_GROUP) | df_encoded[\"SUBGROUP\"].str.contains(PRODUCT_GROUP)\n",
    "filtered_df = df_encoded[boolean_filter_pid]\n",
    "print(f'Number of \"{PRODUCT_GROUP}\" transactions found: {filtered_df.shape[0]}\\n')\n",
    "\n",
    "\n",
    "#===========  Calculate_ALL: MAT ============#\n",
    "#Calcualte the MAT for PRODUCT_GROUP\n",
    "df_MAT = calculate_mat(filtered_df, PRODUCT_GROUP)\n",
    "temp_data_0 = df_MAT #temp data for plot\n",
    "\n",
    "#Calcualte the MAT for GROUPs & Regions\n",
    "if productIdx == 0:\n",
    "    df_MAT_group = calculate_mat_group(filtered_df, 'GROUP')\n",
    "\n",
    "#Calcualte the MAT for Regions\n",
    "df_MAT_region = calculate_mat_group(filtered_df, 'Region')\n",
    "\n",
    "\n",
    "#========  Calculate_ALL: Sales Trend ========#\n",
    "#Calculate q repoort df for PRODUCT_GROUP\n",
    "q_report_df = generate_q_sales_report(df_MAT, PRODUCT_GROUP)\n",
    "\n",
    "\n",
    "#========  Calculate ALL: QTD Sales by Product ========#\n",
    "#Calculate QTD Sales by PRODUCT_GROUP \n",
    "qtd_sales_license_seat = generate_qtd_sales_by_license(filtered_df, PRODUCT_GROUP)\n",
    "\n",
    "\n",
    "#==========  Calculate ALL: Sales by Region =========#\n",
    "#Calculate Sales by Region and Quarter \n",
    "sales_by_region_and_q = calculate_sales_by_region_and_quarter(filtered_df, PRODUCT_GROUP)\n",
    "temp_data_1 = sales_by_region_and_q #temp data for plot\n",
    "#Calculate Sales by Region and License \n",
    "sales_by_region_and_lic = calculate_sales_by_region_and_lic(filtered_df, PRODUCT_GROUP)\n",
    "temp_data_2 = sales_by_region_and_lic #temp data for plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMfVhn2mfbO1"
   },
   "source": [
    "Each Product in Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnCbkhvaVqbR"
   },
   "outputs": [],
   "source": [
    "#If there are more than one product in the group\n",
    "if len(group_dct.values()) > 1:\n",
    "\n",
    "  #For product in the group, except the first one\n",
    "  for item in list(group_dct.values()):\n",
    "    \n",
    "    #========== Filter: by Articles =========#\n",
    "    #Filter df_encoded by product article keywords\n",
    "    boolean_filter_pid = df_encoded[\"CD\"].str.contains(item) | df_encoded[\"SUBGROUP\"].str.contains(item)\n",
    "    filtered_df = df_encoded[boolean_filter_pid]\n",
    "   \n",
    "\n",
    "    #===========  Calculate: MAT ============#\n",
    "    #Calculate MAT for the new filtered df\n",
    "    df_MAT_new = calculate_mat(filtered_df, item)\n",
    "    df_MAT_all_periods = add_missing_month_MAT(df_MAT_new, temp_data_0)\n",
    "    #Append the new MAT dataframe to the end of df_MAT\n",
    "    df_MAT = pd.concat([df_MAT, df_MAT_all_periods], axis=0)\n",
    "    \n",
    "\n",
    "    #========  Calculate: Sales Trend ========#\n",
    "    #Calculate q repoort df for the new filtered df\n",
    "    q_report_df_new = generate_q_sales_report(df_MAT_new, item)\n",
    "    #Append the new q repoort df dataframe to the q repoort df\n",
    "    q_report_df = pd.concat([q_report_df, q_report_df_new], axis=0)   \n",
    "\n",
    "    #========  Calculate: QTD Sales by Product ========#\n",
    "    #Calculate QTD Sales by PRODUCT_GROUP \n",
    "    qtd_sales_license_seat_new = generate_qtd_sales_by_license(filtered_df, item)\n",
    "    qtd_sales_license_seat = pd.concat([qtd_sales_license_seat, qtd_sales_license_seat_new], axis=0)\n",
    "    #Plot QTD sales by license\n",
    "    plot_qtd_sales_license(qtd_sales_license_seat_new, DIRECTORY, item,  False)\n",
    "    \n",
    "\n",
    "    #==========  Calculate ALL: Sales by Region =========#\n",
    "    #Calculate Sales by Region and Quarter \n",
    "    sales_by_region_and_q_new = calculate_sales_by_region_and_quarter(filtered_df, item)\n",
    "    sales_by_region_and_q = pd.concat([sales_by_region_and_q, sales_by_region_and_q_new], axis=0)  \n",
    "    #Plot Sales by Region & Quarter\n",
    "    plot_sales_by_region(sales_by_region_and_q_new,item, DIRECTORY, False, 'QTD_Encoding')\n",
    "        \n",
    "    #Calculate Sales by Region and License\n",
    "    sales_by_region_and_lic_new = calculate_sales_by_region_and_lic(filtered_df, item)\n",
    "    sales_by_region_and_lic = pd.concat([sales_by_region_and_lic, sales_by_region_and_lic_new], axis=0)\n",
    "\n",
    "    #Plot Sales by Region & Quarter\n",
    "    plot_sales_by_region(sales_by_region_and_lic,item, DIRECTORY, False, 'EID_GROUP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0arWvhbCOLpq"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9t1VlEeZaplk"
   },
   "outputs": [],
   "source": [
    "plot_MAT(df_MAT, PRODUCT_GROUP, DIRECTORY, True, 0, 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xA-SFo96x9Af"
   },
   "outputs": [],
   "source": [
    "label1 = PRODUCT_GROUP + ' by Group'\n",
    "label2 = PRODUCT_GROUP + ' by Region'\n",
    "\n",
    "if productIdx == 0:\n",
    "    plot_MAT(df_MAT_group, label1, DIRECTORY, True, 0,'tab10')\n",
    "    print('')\n",
    "plot_MAT(df_MAT_region, label2, DIRECTORY, True, 0, 'tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiwRIks_OXbE"
   },
   "outputs": [],
   "source": [
    "plot_q_sales_trend(q_report_df, DIRECTORY, PRODUCT_GROUP, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhJho7PDYniq"
   },
   "outputs": [],
   "source": [
    "plot_sales_by_region(temp_data_1, PRODUCT_GROUP, DIRECTORY, True, 'QTD_Encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyiiZwxG2asJ"
   },
   "outputs": [],
   "source": [
    "plot_qtd_sales_license(qtd_sales_license_seat, DIRECTORY, PRODUCT_GROUP,  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptENpTiYaSUE"
   },
   "outputs": [],
   "source": [
    "plot_sales_by_region(temp_data_2, PRODUCT_GROUP, DIRECTORY, True, 'EID_GROUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZw-knNGxZOk"
   },
   "outputs": [],
   "source": [
    "plot_qtd_sales_region(temp_data_1, PRODUCT_GROUP, DIRECTORY, True, 'tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OTPLth6MDt8"
   },
   "source": [
    "## Write to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTV15AOEOLCG"
   },
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbkBRxbIxVsm"
   },
   "outputs": [],
   "source": [
    "#reshape MAT data\n",
    "excel_MAT_WW = reshape_excel_plot_MAT(df_MAT)\n",
    "excel_MAT_byRegion = reshape_excel_plot_MAT(df_MAT_region)\n",
    "excel_MAT_byGroup = reshape_excel_plot_MAT(df_MAT_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1atJ2l0CWvq"
   },
   "outputs": [],
   "source": [
    "#reshape quarterly short term sales trend\n",
    "excel_q_report_df = q_report_df.set_index('Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNG3AUX0Nq0t"
   },
   "outputs": [],
   "source": [
    "#reshape QTD sales&seat by licese\n",
    "excel_qtd_sales_license_seat = qtd_sales_license_seat.set_index('Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyPhsrs-4eFn"
   },
   "outputs": [],
   "source": [
    "#reshape QTD sakes by license \n",
    "excel_qtd_sales_license = qtd_sales_license_seat.loc[qtd_sales_license_seat['Unit'] != 'Seat (Qty)'] #drop \"Seat(Qty)\"\n",
    "excel_qtd_sales_license = excel_qtd_sales_license.drop(columns = ['Unit']) #drop \"Unit\"\n",
    "excel_qtd_sales_license.set_index('Product', inplace = True) #set roduct as index\n",
    "\n",
    "#calculate percetage per product\n",
    "excel_qtd_sales_license_pct = excel_qtd_sales_license.iloc[:, 0:].apply(lambda x: x/x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj3N81VC2jw-"
   },
   "outputs": [],
   "source": [
    "#reshpa sales by region\n",
    "excel_by_region_reshaped = reshape_sales_by_region(sales_by_region_and_lic)\n",
    "excel_by_region_reshaped_pct = excel_by_region_reshaped.apply(lambda x: x/x.sum(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPi6M89hORFj"
   },
   "source": [
    "Write to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAMaZi-ojsJu"
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(DIRECTORY + '/_' + PRODUCT_GROUP + '_Excel_Report.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to one ksheet.\n",
    "    excel_MAT_WW.to_excel(writer, sheet_name='MAT_WW')\n",
    "    excel_MAT_byRegion.to_excel(writer, sheet_name='MAT_Region')\n",
    "    excel_MAT_byGroup.to_excel(writer, sheet_name='MAT_Group')\n",
    "    excel_q_report_df.to_excel(writer, sheet_name='ShortTerm_Trend')\n",
    "    excel_qtd_sales_license_seat.to_excel(writer, sheet_name='QTD_bySeat_byLic')\n",
    "    excel_qtd_sales_license.to_excel(writer, sheet_name='QTD_byLic')\n",
    "    excel_qtd_sales_license_pct.to_excel(writer, sheet_name='QTD_byLic_pct')\n",
    "    excel_by_region_reshaped.to_excel(writer, sheet_name='QTD_byRegion')\n",
    "    excel_by_region_reshaped_pct.to_excel(writer, sheet_name='QTD_byRegion_pct')\n",
    "    sales_by_region_and_lic.to_excel(writer, sheet_name='QTD_Region_byLic')\n",
    "    sales_by_region_and_q.to_excel(writer, sheet_name='ShortTerm_Trend_byRegion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leeOm-PRfK9Q"
   },
   "source": [
    "## File Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFx1Q03Re1_s"
   },
   "outputs": [],
   "source": [
    "print(DIRECTORY)\n",
    "#============== WARNING ================#\n",
    "#-------- Deletes Reports Folder --------#\n",
    "DELETE_ALL = False\n",
    "if DELETE_ALL is True:\n",
    "  #============== WARNING ================#\n",
    "  shutil.rmtree('/content/QBR_REPORTS', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2g7ycuE7dMYU"
   },
   "outputs": [],
   "source": [
    "#Zip all reports\n",
    "#Run after generating repots for all\n",
    "TO_ZIP = False\n",
    "if TO_ZIP == True:\n",
    "    !zip -r '/content/QBR_REPORTS/QBR_Reports.zip' '/content/QBR_REPORTS'\n",
    "    print('The zip file is successfully created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwF7a-6Cp9CX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhF5wWcqglCT"
   },
   "source": [
    "Report Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAvG5BN2XOpF"
   },
   "outputs": [],
   "source": [
    "#Reporting message\n",
    "print(f'Reports generated for Product Group {productIdx} \\n---------------------------------------')\n",
    "print('All: '+ PRODUCT_GROUP)\n",
    "print(''.join(\"{0}\\n\".format(x) for x in group_dct.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Llphc4Rzvb5U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_POi30gWKXUC",
    "7HXEZb2vKoH0",
    "ANZ4iKTiK1xP",
    "54LHVT2HKMvd",
    "SCHN5gIALJ6Z",
    "VNWtQIEkLjIh"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
