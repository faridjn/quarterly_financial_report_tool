{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMSgAF7PYuAM"
      },
      "source": [
        "Author: Farid Javadnejad\\\n",
        "Institution: Leica Geosystems\\\n",
        "Latest Update: 1/22/2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2PLCIfD8tb0"
      },
      "source": [
        "#Leica RC: QBR Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPCOkHOnu872"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ydWZ0j-YoHO"
      },
      "outputs": [],
      "source": [
        "# Import NumPy, Pandas, PyPlot SeaBorn libs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as tick\n",
        "import seaborn as sns\n",
        "\n",
        "# Import Google Colab filer upload libs\n",
        "import io\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "# Import Google Sheet access authentication libs\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "#Files & folders\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "#time\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import MonthEnd\n",
        "\n",
        "#Excel file handling\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter\n",
        "\n",
        "# notifier\n",
        "from IPython.display import Javascript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUqWoH02Inu"
      },
      "source": [
        "\n",
        "Global: Colors & Font Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48v-qzkmvV0w"
      },
      "outputs": [],
      "source": [
        "#Colors\n",
        "global COLOR_SET_google\n",
        "COLOR_SET_google = ['#F3C302', '#4486F4', '#51B457', '#E44B31', '#808080']\n",
        "\n",
        "#Set default font size\n",
        "global FONT_SIZE\n",
        "FONT_SIZE = \"13\"\n",
        "\n",
        "\n",
        "global PALLETE\n",
        "PALLETE = ['viridis', 'magma', 'plasma', 'tab20', 'tab10', 'paired']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Xxxx3hFmQ9"
      },
      "source": [
        "Global: Directory and Regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk32txOQC92u"
      },
      "outputs": [],
      "source": [
        "#Define global variables\n",
        "global PROCESS_MONTH\n",
        "\n",
        "global DIRECTORY\n",
        "\n",
        "\n",
        "#create a list of all Regions\n",
        "global ALL_REGIONS\n",
        "ALL_REGIONS = ['LATAM', 'EM EMEA', 'India', 'Nordics', 'Russia', 'ANZ', 'China', 'Asia', 'UK/BX', 'Central EU','South EU','US/CA']\n",
        "\n",
        "global ALL_PANREGIONS\n",
        "ALL_PANREGIONS = {'LATAM': 'AMER',\n",
        "    'EM EMEA': 'EU',\n",
        "    'India': 'ANZ+India',\n",
        "    'Nordics': 'EU',\n",
        "    'ANZ': 'ANZ+India',\n",
        "    'China': 'China',\n",
        "    'Asia': 'Asia',\n",
        "    'UK/BX': 'EU',\n",
        "    'Central EU': 'EU',\n",
        "    'South EU': 'EU',\n",
        "    'US/CA': 'AMER',\n",
        "    'Russia': 'Russia'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnH10_bb8-BX"
      },
      "source": [
        "## Custom Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_POi30gWKXUC"
      },
      "source": [
        "###Color Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIQukbC2r3wV"
      },
      "source": [
        "f: Color Picker Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gev5vSx8VHPd"
      },
      "outputs": [],
      "source": [
        "def gradient_color_picker(i,n, pallete = 'PALLETE'):\n",
        "\n",
        "  magma = ['#000004', '#120d31', '#331067', '#59157e', '#7e2482', '#a3307e', '#c83e73', '#e95462', '#fa7d5e',' #fea973', '#fed395', '#fcfdbf']\n",
        "\n",
        "  tab20 = ['#1f77b4', '#17becf', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b',\n",
        "           '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d', '#6baed6', '#9edae5']\n",
        "\n",
        "  tab10 = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22','#17becf']\n",
        "\n",
        "  viridis = ['#440154', '#481b6d', '#46327e', '#3f4788', '#365c8d', '#2e6e8e', '#277f8e', '#21918c',\n",
        "             '#1fa187', '#2db27d', '#4ac16d', '#73d056', '#a0da39', '#d0e11c', '#fde725']\n",
        "\n",
        "  plasma = ['#0d0887', '#350498', '#5302a3', '#6f00a8', '#8b0aa5', '#a31e9a', '#b83289', '#cc4778', '#db5c68',\n",
        "          '#e97158', '#f48849', '#fba238', '#febd2a', '#fada24', '#f0f921']\n",
        "\n",
        "  paired =['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c',\n",
        "           '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928']\n",
        "\n",
        "\n",
        "  if pallete == 'viridis':\n",
        "    pallete = viridis\n",
        "  elif pallete == 'plasma':\n",
        "    pallete = plasma\n",
        "  elif pallete == 'tab20':\n",
        "    pallete = tab20\n",
        "  elif pallete == 'tab10':\n",
        "    pallete = tab10\n",
        "  else:\n",
        "    pallete = magma\n",
        "\n",
        "  sizeOfList = len(pallete) - 1\n",
        "  if n < 0 or n > sizeOfList:\n",
        "    raise ValueError #The accepted values are between 0 - {sizeOfList}\n",
        "\n",
        "  if i > n:\n",
        "    raise ValueError #i can not be larget than {sizeOfList}\n",
        "\n",
        "  idx = sizeOfList*i//n\n",
        "\n",
        "  return pallete[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HXEZb2vKoH0"
      },
      "source": [
        "###Reading Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCQwFZsBmVqI"
      },
      "source": [
        "Generate Keyword from List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdYxkDPumeJE"
      },
      "outputs": [],
      "source": [
        "def keyword_from_list(li: list):\n",
        "  ''' Gets a list of strings and returns one string as keyword'''\n",
        "\n",
        "  str_list = filter(lambda item: item !='', li)  #remove empty items from list\n",
        "  key_words ='|'.join(str_list)  #keyword Generator\n",
        "  return key_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_CKew1smhZ8"
      },
      "source": [
        "Goolge Workbook to DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFZmFZMrmftK"
      },
      "outputs": [],
      "source": [
        "def workbook_to_dataframe(work_book, work_sheet):\n",
        "  '''Gets a GoogleSheet workbook and worksheet name oand retrun a dataframe'''\n",
        "\n",
        "  ws = work_book.worksheet(work_sheet) #read the worksheet\n",
        "  rows = ws.get_all_values() #get_all_values gives a list of rows\n",
        "  df = pd.DataFrame.from_records(rows) #create a dataframe from all values\n",
        "  df.replace('', np.nan) #data cleanup\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSz3a37wm3Rn"
      },
      "source": [
        "\n",
        "f: Read GoogleSheet by URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR3kJkekm6vV"
      },
      "outputs": [],
      "source": [
        "def read_gs_by_url(url: str):\n",
        "  ''' Read a workbook by url '''\n",
        "\n",
        "  gc = gspread.authorize(creds)\n",
        "  wb = gc.open_by_url(url)\n",
        "  return wb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdSNaglanD1Q"
      },
      "source": [
        "f: Cast df colum to a dictionry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qISc0HJCnDFV"
      },
      "outputs": [],
      "source": [
        "def column_to_dict(column, output = True):\n",
        "  ''' Cast dataframe columnto a dictionry '''\n",
        "  dct = {}\n",
        "  i = 0\n",
        "  for item in column:\n",
        "    if item != '':\n",
        "      dct[i]= item\n",
        "      i +=1\n",
        "  if output:\n",
        "    for a,b in dct.items():\n",
        "      print(a, ':', b)\n",
        "  return dct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANZ4iKTiK1xP"
      },
      "source": [
        "### Pre-processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2DWc9Finiwa"
      },
      "source": [
        "f: Replace df header with 1st row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FUniZNjniPR"
      },
      "outputs": [],
      "source": [
        "def dataframe_header(df: pd.DataFrame):\n",
        "   ''' Python Pandas Replacing Header with Top Row '''\n",
        "   df_header = df.iloc[0] #grab the first row for the header\n",
        "   df = df[1:] #take the data less the header row\n",
        "   df.columns = df_header #set the header row as the df header\n",
        "   return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwQzu003CBqq"
      },
      "source": [
        "f: Get YYYY-MM from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyl6ot3qB9ye"
      },
      "outputs": [],
      "source": [
        "def format_month(date_string):\n",
        "    parts = date_string.split('.')\n",
        "    month = str(int(parts[0])).zfill(2)\n",
        "    year = parts[1]\n",
        "    formatted_date = f\"{year}-{month}\"\n",
        "    return formatted_date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEoph-o2NomQ"
      },
      "source": [
        "f: Clean-up & Rename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vNWJBVCNZ4X"
      },
      "outputs": [],
      "source": [
        "def clean_qty(df):\n",
        "    if 'Qty' in df.columns:\n",
        "        replace_list = [' PC.', ' AU', ',', 'WK', 'YR', '*']\n",
        "        for label in replace_list:\n",
        "            df['Qty'] = df['Qty'].replace(label, '')\n",
        "        df['Qty'] = df['Qty'].replace('', np.nan).fillna(0)\n",
        "    return df\n",
        "\n",
        "def filter_regions(df):\n",
        "    if 'Region' in df.columns:\n",
        "        world_sales_filter = df['Region'].str.contains(\"World GEO\").fillna(False)\n",
        "        df = df.loc[~world_sales_filter.values]\n",
        "    return df\n",
        "\n",
        "def clean_region_names(df):\n",
        "    if 'Region' in df.columns:\n",
        "        df.loc[:, 'Region'] = df['Region'].str.replace('GSR', '')\n",
        "        df.loc[:, 'Region'] = df['Region'].str.replace('US/CAN', 'US/CA')\n",
        "        df.loc[:, 'Region'] = df['Region'].str.replace('Europe', 'EU')\n",
        "        df.loc[:, 'Region'] = df['Region'].str.replace('Emerging', 'EM')\n",
        "    return df\n",
        "\n",
        "def convert_to_numeric(df):\n",
        "    for column in ['Billing', 'Sales', 'Qty']:\n",
        "        if column in df.columns:\n",
        "            df[column] = df[column].astype(float)\n",
        "    return df\n",
        "\n",
        "def manage_dates(df):\n",
        "    if 'MM_YY' in df.columns:\n",
        "        df = df.copy()\n",
        "        df = df[df['MM_YY'].astype(str).str.match(r'^\\D')==False]\n",
        "        df['MM_YY'] = df['MM_YY'].str.lstrip('0')\n",
        "        df = df.dropna(subset=['MM_YY'])\n",
        "        df['Date'] = pd.to_datetime(df['MM_YY'], format='%m.%Y')\n",
        "        df['Date'] = df['Date'] + MonthEnd(1)\n",
        "        cols = df.columns.tolist()\n",
        "        cols.insert(0, cols.pop(cols.index('Date')))\n",
        "        df = df[cols]\n",
        "    return df\n",
        "\n",
        "def drop_non_numeric_rows(df, column_name):\n",
        "    # Copy the original DataFrame to avoid modifying it in place\n",
        "    new_df = df.copy()\n",
        "\n",
        "    # Use pd.to_numeric to convert the values in the specified column to numeric, setting errors='coerce' to convert non-numeric values to NaN\n",
        "    new_df[column_name] = pd.to_numeric(new_df[column_name], errors='coerce')\n",
        "\n",
        "    # Use boolean indexing to drop rows where the specified column contains NaN values\n",
        "    new_df = new_df.dropna(subset=[column_name])\n",
        "\n",
        "    return new_df\n",
        "\n",
        "\n",
        "\n",
        "def cleanup_and_rename(df, header=1):\n",
        "\n",
        "    df = df.copy()\n",
        "    # Drop the specified number of rows from the DataFrame\n",
        "    df.drop(df.index[range(header)], inplace=True)\n",
        "\n",
        "    print(f'Shape Before: {df.shape}')\n",
        "\n",
        "    df = clean_qty(df)\n",
        "    df = filter_regions(df)\n",
        "    df = clean_region_names(df)\n",
        "    df = convert_to_numeric(df)\n",
        "    df = manage_dates(df)\n",
        "    df = drop_non_numeric_rows(df, 'PID')  #remove non numeric `Article Numbers`\n",
        "\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    if 'Region_ID' in df.columns and 'MM_YY' in df.columns:\n",
        "        df.drop(columns= ['Region_ID', 'MM_YY'], inplace = True)\n",
        "\n",
        "    df.reset_index(drop = True, inplace = True)\n",
        "    print(f'Shape After: {df.shape}','\\n')\n",
        "    display(df.head())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyfFYvyGnp5Z"
      },
      "source": [
        "f: Get User Input (Integer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cClNWJBbnpKv"
      },
      "outputs": [],
      "source": [
        "def get_user_input_int(lower: int, upper: int):\n",
        "  '''User input to select the product'''\n",
        "\n",
        "  while True:\n",
        "      try:\n",
        "          val = int(input('\\nEnter an integer value: '))\n",
        "          if val < lower or val > upper:\n",
        "              raise ValueError #this will send it to the print message and back to the input option\n",
        "          break\n",
        "      except ValueError:\n",
        "          print(f\"INVALID: The number must be between ({lower} - {upper}).\")\n",
        "  return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSSYjaMsLtOu"
      },
      "source": [
        "f: Add Q, Year, m_in_Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFSGf6LDLOQ7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def add_q_year_month(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Adds Quarter (Q), Year, and month within the quarter (m_in_Q) columns to the DataFrame.\n",
        "\n",
        "  Args:\n",
        "      df (DataFrame): Input DataFrame with a 'MM_YY' column.\n",
        "\n",
        "  Returns:\n",
        "      DataFrame: Modified DataFrame with Quarter, Year, and m_in_Q columns.\n",
        "\n",
        "  Notes:\n",
        "      - Deletes rows without valid 'MM_YY' data.\n",
        "      - 'MM_YY' column format: 'MM_YY' (e.g., '01_21' for January 2021).\n",
        "      - Q column: Month value divided by 3, rounded up.\n",
        "      - Year column: Last four characters of 'MM_YY' converted to integer.\n",
        "      - m_in_Q column: Month value minus Q multiplied by 3 plus 3.\n",
        "\n",
        "  Example:\n",
        "      df = pd.DataFrame({'MM_YY': ['01_21', '04_21', '07_21', '10_21', '01_22']})\n",
        "      modified_df = add_q_year_month(df)\n",
        "      print(modified_df)\n",
        "\n",
        "      Output:\n",
        "          MM_YY  Q  Year  m_in_Q\n",
        "      0  01_21  1  2021       1\n",
        "      1  04_21  2  2021       2\n",
        "      2  07_21  3  2021       3\n",
        "      3  10_21  4  2021       1\n",
        "      4  01_22  1  2022       1\n",
        "  \"\"\"\n",
        "\n",
        "  #Delete rows without valid 'MM_YY' data\n",
        "  df = df[df['MM_YY'].str.get(0).isin(['0'])==True]\n",
        "\n",
        "  #Define Quarter column\n",
        "  df['Q'] = (df['MM_YY'].str[1:3].astype(float)/3).apply(np.ceil).astype(int)\n",
        "  #Define Year column\n",
        "  df['Year'] = df['MM_YY'].str[-4:].astype(int)\n",
        "  df['m_in_Q'] = (df['MM_YY'].str[1:3].astype(int))-df['Q']*3 + 3\n",
        "\n",
        "  #sort by Year, Q, m_in_Q\n",
        "  df = df.sort_values(by=['Year', 'Q', 'm_in_Q'])\n",
        "\n",
        "  return df\n",
        "  '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsxDR6xen7Qd"
      },
      "source": [
        "f: QTD, PreQTD, LYQTD Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWibtDQcn6Hz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def qtd_encoder(df: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  This function add QTD, PreQTD, LYQTD Encoding for the sales report dataframe\n",
        "  Three filters are created to identify rows that match specific conditions:\n",
        "    - qtd_filter: selects rows from the current quarter and year.\n",
        "    - preqtd_filter: selects rows from the previous quarter and year, up to and including the current month within the quarter.\n",
        "    - lyqtd_filter: selects rows from the same quarter in the previous year, up to and including the current month within the quarter.\n",
        "  \"\"\"\n",
        "\n",
        "  df_encoded = df.copy()\n",
        "\n",
        "  #Create a new colum to classify QTD\n",
        "  df_encoded['QTD_Encoding'] = 'O'\n",
        "\n",
        "  #get the current Year, Quarter, and month in Quarter\n",
        "  current_q = df['Q'].iloc[-1]\n",
        "  current_yr = df['Year'].iloc[-1]\n",
        "  current_m_in_Q = df['m_in_Q'].iloc[-1]\n",
        "  print(f'Current qaurter is:\\nQ = {current_q}\\nYear = {current_yr}\\nm_in_Q = {current_m_in_Q}\\n')\n",
        "\n",
        "  #create a filter for current quarter-to-date (QTD)\n",
        "  qtd_filter = (df['Q'] == current_q) & (df['Year'] == current_yr)\n",
        "\n",
        "  ################\n",
        "  #print(qtd_filter[:10])\n",
        "\n",
        "  #create a filter for previous quarter-to-date (PreQTD)\n",
        "  preqtd_filter = (df['Q'] == current_q - 1) & (df['Year'] == current_yr) & (df['m_in_Q'] <= current_m_in_Q)\n",
        "\n",
        "  if current_q == 1:\n",
        "    preqtd_filter = (df['Q'] == 4) & (df['Year'] == (current_yr -1)) & (df['m_in_Q'] <= current_m_in_Q)\n",
        "\n",
        "\n",
        "  ################\n",
        "  #print(preqtd_filter[:10])\n",
        "\n",
        "  #create a filter for last year quarter-to-date (LYQTD)\n",
        "  lyqtd_filter = (df['Q'] == current_q) & (df['Year'] == (current_yr-1)) & (df['m_in_Q'] <= (current_m_in_Q))\n",
        "\n",
        "  ################\n",
        "  #print(lyqtd_filter[:10])\n",
        "\n",
        "  df_encoded.loc[qtd_filter, 'QTD_Encoding'] = 'QTD'\n",
        "  df_encoded.loc[preqtd_filter, 'QTD_Encoding'] = 'PreQTD'\n",
        "  df_encoded.loc[lyqtd_filter, 'QTD_Encoding'] = 'LYQTD'\n",
        "\n",
        "\n",
        "  return df_encoded\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGIOM4xI_TOY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def ytd_encoder(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Adds LYTD and YTD encoding for the sales report DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Input DataFrame with columns 'Q', 'Year', and 'm_in_Q'.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Modified DataFrame with additional 'YTD_Encoding' column.\n",
        "\n",
        "    Notes:\n",
        "        - The 'YTD_Encoding' column categorizes each row as 'YTD' or 'LYTD' based on specific conditions.\n",
        "        - Two filters are created to identify rows that match specific conditions:\n",
        "            - ytd_filter: Selects rows from the current year up to and including the current month.\n",
        "            - lytd_filter: Selects rows from the previous year up to and including the current month.\n",
        "        - The function assumes that the input DataFrame contains columns 'Q' (quarter), 'Year', and 'm_in_Q' (month within the quarter).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_encoded = df.copy()\n",
        "\n",
        "    # Create a new column to classify YTD\n",
        "    df_encoded['YTD_Encoding'] = 'O'\n",
        "\n",
        "    # Get the current Year, Quarter, and month in Quarter\n",
        "    current_q = df['Q'].iloc[-1]\n",
        "    current_yr = df['Year'].iloc[-1]\n",
        "    current_m_in_Q = df['m_in_Q'].iloc[-1]\n",
        "    print(f'Current quarter is:\\nQ = {current_q}\\nYear = {current_yr}\\nm_in_Q = {current_m_in_Q}\\n')\n",
        "\n",
        "    # Create a filter for current year-to-date (YTD)\n",
        "    ytd_filter = (df['Year'] == current_yr) & (df['m_in_Q'] <= current_m_in_Q) & (df['Q'] <= current_q)\n",
        "\n",
        "    # Create a filter for last year-to-date (LYTD)\n",
        "    lytd_filter = (df['Year'] == current_yr - 1) & (df['m_in_Q'] <= current_m_in_Q) & (df['Q'] <= current_q)\n",
        "\n",
        "    df_encoded.loc[ytd_filter, 'YTD_Encoding'] = 'YTD'\n",
        "    df_encoded.loc[lytd_filter, 'YTD_Encoding'] = 'LYTD'\n",
        "\n",
        "    return df_encoded\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOtOA1WGU7OB"
      },
      "outputs": [],
      "source": [
        "#### NEW ENCODER ####\n",
        "def encode_ytd(df, max_date):\n",
        "    # Create 'YTD' column, label as 1 if the date belongs to the current year, else 0\n",
        "    df['YTD'] = df['Date'].apply(lambda x: 1 if x.year == max_date.year and x <= max_date else 0)\n",
        "    return df\n",
        "\n",
        "def encode_lytd(df, lytd_date):\n",
        "    # Create 'LYTD' column, label as 1 if the date belongs to the last year and up to the current day, else 0\n",
        "    df['LYTD'] = df['Date'].apply(lambda x: 1 if x.year == lytd_date.year and x <= lytd_date else 0)\n",
        "    return df\n",
        "\n",
        "def encode_qtd(df, max_date):\n",
        "    # Create 'QTD' column, label as 1 if the date belongs to the current quarter, else 0\n",
        "    df['QTD'] = df['Date'].apply(lambda x: 1 if (x.year == max_date.year and x.quarter == max_date.quarter) else 0)\n",
        "    return df\n",
        "\n",
        "def encode_lyqtd(df, lyqtd_date):\n",
        "    # Create 'LYQTD' column, label as 1 if the date belongs to the same quarter of the previous year and up to the current day, else 0\n",
        "    df['LYQTD'] = df['Date'].apply(lambda x: 1 if x.year == lyqtd_date.year and x.quarter == lyqtd_date.quarter and x <= lyqtd_date else 0)\n",
        "    return df\n",
        "\n",
        "# Function to calculate PreQTD\n",
        "def encode_lqtd(df, max_date):\n",
        "    # Calculate lqtd_date and lqtd_start_date as before\n",
        "\n",
        "    # Calculate Quarter ('Q'), Year ('Y'), and Month in Quarter ('mQ') from 'Date' column\n",
        "    df['Q'] = df['Date'].dt.quarter\n",
        "    df['Y'] = df['Date'].dt.year\n",
        "    df['mQ'] = df['Date'].dt.month - (df['Q'] - 1) * 3\n",
        "\n",
        "    # Determine the current quarter, year, and months in the current quarter\n",
        "    current_quarter = (max_date.month - 1) // 3 + 1\n",
        "    current_year = max_date.year\n",
        "    current_month_in_quarter = max_date.month - (current_quarter - 1) * 3\n",
        "\n",
        "    # Define a filter for the previous quarter-to-date (PreQTD)\n",
        "    preqtd_filter = (\n",
        "        (df['Q'] == current_quarter - 1) &\n",
        "        (df['Y'] == current_year) &\n",
        "        (df['mQ'] <= current_month_in_quarter)\n",
        "    )\n",
        "\n",
        "    if current_quarter == 1:\n",
        "        preqtd_filter = (\n",
        "            (df['Q'] == 4) &\n",
        "            (df['Y'] == (current_year - 1)) &\n",
        "            (df['mQ'] <= current_month_in_quarter)\n",
        "        )\n",
        "\n",
        "    # Create 'PreQTD' column and flag months that belong to PreQTD with 1\n",
        "    df['PreQTD'] = 0\n",
        "    df.loc[preqtd_filter, 'PreQTD'] = 1\n",
        "\n",
        "    # Drop the temporary columns\n",
        "    df.drop(['Q', 'Y', 'mQ'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "import calendar\n",
        "def encode_year_quarter(df):\n",
        "    # Determine Max Date Value\n",
        "    max_date = df['Date'].max()\n",
        "\n",
        "    # Get the same day of the year in the previous year and the corresponding day of the quarter in the previous year\n",
        "    # Adjust the day to 28 if the month is February and the day is 29 in a non-leap year\n",
        "    if max_date.month == 2 and max_date.day == 29 and not calendar.isleap(max_date.year - 1):\n",
        "        lytd_date = lyqtd_date = pd.Timestamp(year=max_date.year-1, month=max_date.month, day=28)\n",
        "    else:\n",
        "        lytd_date = lyqtd_date = pd.Timestamp(year=max_date.year-1, month=max_date.month, day=max_date.day)\n",
        "\n",
        "    df = encode_ytd(df, max_date)\n",
        "    df = encode_lytd(df, lytd_date)\n",
        "    df = encode_qtd(df, max_date)\n",
        "    df = encode_lyqtd(df, lyqtd_date)\n",
        "    df = encode_lqtd(df, max_date)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiHgVs_uZ6lf"
      },
      "outputs": [],
      "source": [
        "def add_encoding_columns(df):\n",
        "    # Create 'QTD_Encoding' column {'QTD', 'LYQTD', 'PreQTD', 'O}\n",
        "    df['QTD_Encoding'] = df.apply(lambda row: 'QTD' if row['QTD'] == 1 else ('LYQTD' if row['LYQTD'] == 1 else ('PreQTD' if row['PreQTD'] == 1 else 'O')), axis=1)\n",
        "\n",
        "    # Create 'YTD_Encoding' column {'YTD', 'LYTD', 'O'}\n",
        "    df['YTD_Encoding'] = df.apply(lambda row: 'YTD' if row['YTD'] == 1 else ('LYTD' if row['LYTD'] == 1 else 'O'), axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54LHVT2HKMvd"
      },
      "source": [
        "###Calculations Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obNGk1ktn58B"
      },
      "source": [
        "f: Calcualte MAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKOJPTgXYppA"
      },
      "outputs": [],
      "source": [
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "def calculate_mat(data_frame: pd.DataFrame, product_name:str):\n",
        "  \"\"\"This function gets a sales dataframe that includes QTD Encoding and calcuates MAT df \"\"\"\n",
        "  df = data_frame.copy()\n",
        "  # Ensure Date is in datetime format\n",
        "  df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "  # Sort values by Date\n",
        "  df = df.sort_values(by='Date')\n",
        "\n",
        "  # Create a 'YearMonth' column for aggregation\n",
        "  df['YearMonth'] = df['Date'].dt.to_period('M')\n",
        "\n",
        "  # Group by 'YearMonth' and sum 'Sales'\n",
        "  df_grouped = df.groupby(['YearMonth', 'Date', 'QTD_Encoding', 'YTD_Encoding'])[['Sales', 'Billing']].sum().reset_index()\n",
        "\n",
        "  # Compute the 12 month moving average\n",
        "  df_grouped['Sales_MAT'] = df_grouped['Sales'].rolling(window=12).sum()\n",
        "  df_grouped['Billing_MAT'] = df_grouped['Billing'].rolling(window=12).sum()\n",
        "\n",
        "  # Adding a 'Period' column with \"Start Date - End Date\" for 12 month period\n",
        "  df_grouped['Period'] = (df_grouped['YearMonth'].dt.to_timestamp() \\\n",
        "                          - pd.DateOffset(months=11)).dt.to_period('M').astype(str)\\\n",
        "                          +  \" - \" + df_grouped['YearMonth'].astype(str)\n",
        "  df_grouped['Product'] = product_name\n",
        "\n",
        "  # Calculate the minimum and maximum dates in the dataset\n",
        "  min_date = df['Date'].min() + relativedelta(months=10)\n",
        "  max_date = df['Date'].max()\n",
        "\n",
        "  # Apply mask after calculating MAT to limit the results to the desired date range\n",
        "  mask = (df_grouped['Date'] >= min_date) & (df_grouped['Date'] <= max_date)\n",
        "  df_final = df_grouped[mask]\n",
        "\n",
        "  # Return only 'Period' and 'MAT' columns\n",
        "  df_final = df_final[['Product', 'Date', 'Period', 'Sales', 'Billing', 'Billing_MAT', 'Sales_MAT', 'QTD_Encoding', 'YTD_Encoding']]\n",
        "\n",
        "  return df_final\n",
        "\n",
        "  '''\n",
        "  #Aggregate Sales & Billing values\n",
        "  group_data = df.groupby(['MM_YY', 'Q','Year', 'm_in_Q', 'QTD_Encoding', 'YTD_Encoding'],as_index=False)[['Sales', 'Billing']].sum()\n",
        "\n",
        "  #sory by Year, Q, month in Q\n",
        "  group_data = group_data.sort_values(by=['Year', 'Q', 'm_in_Q']).reset_index()\n",
        "  group_data['Billing_MAT'] = group_data.Billing.rolling(window=12).sum()\n",
        "  group_data['Sales_MAT'] = group_data.Sales.rolling(window=12).sum()\n",
        "\n",
        "  # 12 month period for MAT\n",
        "  group_data['Start_Period'] = group_data.MM_YY.shift(periods=11)\n",
        "\n",
        "  # Create period labels\n",
        "  group_data['Period'] = group_data['Start_Period'].str[1:] + ' - ' + group_data['MM_YY'].str[1:]\n",
        "\n",
        "  #df_MAT['Period'].astype(str)\n",
        "  group_data['Billing_MAT'].astype(float)\n",
        "  group_data['Sales_MAT'].astype(float)\n",
        "  group_data['YYYYMM'] = group_data['MM_YY'].astype(str).str[4:] + group_data['MM_YY'].astype(str).str[1:3]\n",
        "  group_data['Date'] = pd.to_datetime(group_data['YYYYMM'], format='%Y%m', errors='coerce') + MonthEnd(1)\n",
        "  group_data['Product'] = product_name\n",
        "\n",
        "  #Subset the dataframe\n",
        "  df_MAT = group_data[['Product', 'Date', 'Sales', 'Billing', 'Period', 'Billing_MAT', 'Sales_MAT', 'QTD_Encoding', 'YTD_Encoding']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return df_MAT\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NanYDlYYegfz"
      },
      "outputs": [],
      "source": [
        "def calculate_mat_group(df: pd.DataFrame, mat_by = 'MAT_by'):\n",
        "\n",
        "  ### TEST ####\n",
        "  #df = filtered_df\n",
        "  #######################\n",
        "\n",
        "  MAT_by = ['PRODUCT_GROUP', 'Region', 'Panregion']\n",
        "\n",
        "  df_MAT = calculate_mat(df, 'CD')\n",
        "\n",
        "  all_GROUP = df[mat_by].unique()\n",
        "  #Aggregate Sales & Billing values\n",
        "\n",
        "  for group in all_GROUP:\n",
        "    if group != 0:\n",
        "      df_GROUP = df[df[mat_by] == group]\n",
        "      df_MAT_GROUP = calculate_mat(df_GROUP, group)\n",
        "      df_MAT = pd.concat([df_MAT, df_MAT_GROUP], axis=0)\n",
        "\n",
        "  return df_MAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2b1qBSKUJVx"
      },
      "source": [
        "f: Caclulate Quarter Sales Trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5imhvgIwUCI1"
      },
      "outputs": [],
      "source": [
        "def generate_q_sales_report(df: pd.DataFrame, product_name:str):\n",
        "  ''' Calculate Quarte Sales Trend report '''\n",
        "\n",
        "  filter_qtd_sales = (df['QTD'] == 1)\n",
        "  filter_preqtd_sales = (df['PreQTD'] == 1)\n",
        "  filter_lyqtd_sales = (df['LYQTD'] == 1)\n",
        "\n",
        "  filter_ytd_sales = (df['YTD'] == 1)\n",
        "  filter_lytd_sales = (df['LYTD'] == 1)\n",
        "\n",
        "\n",
        "  #Sum of Sales for Quarter to Date (QTD)\n",
        "  QTD = (df.loc[filter_qtd_sales].Sales.sum()).astype(float)\n",
        "\n",
        "  #Sum of Sales for Last Year Quarter to Date (LYQTD)\n",
        "  PreQTD = (df.loc[filter_preqtd_sales].Sales.sum()).astype(float)\n",
        "\n",
        "  #Sum of Sales for Last Year Quarter to Date (LYQTD)\n",
        "  LYQTD = (df.loc[filter_lyqtd_sales].Sales.sum()).astype(float)\n",
        "\n",
        "  YTD = (df.loc[filter_ytd_sales].Sales.sum()).astype(float)\n",
        "  LYTD = (df.loc[filter_lytd_sales].Sales.sum()).astype(float)\n",
        "\n",
        "  # Data of lists.\n",
        "  q_report_data = {'Product':[product_name],\n",
        "          'QTD(kEUR)':[QTD/1000],  #convert to kEUR\n",
        "          'PreQTD(kEUR)':[PreQTD/1000], #convert to kEUR\n",
        "          'LYQTD(kEUR)':[LYQTD/1000], #convert to kEUR\n",
        "          'YTD(kEUR)':[YTD/1000], #convert to kEUR\n",
        "          'LYTD(kEUR)':[LYTD/1000], #convert to kEUR\n",
        "          'Rel_PreQTD(%)':[(100*QTD/PreQTD).astype(int)], #convert to %\n",
        "          'Rel_LYQTD(%)':[(100*QTD/LYQTD).astype(int)], #convert to %\n",
        "          'Rel_LYTD(%)':[(100*YTD/LYTD).astype(int)] #convert to %\n",
        "                   }\n",
        "\n",
        "  # Create Q Report DataFrame\n",
        "  q_report_df = pd.DataFrame(q_report_data)\n",
        "  q_report_df = q_report_df.round({'QTD(kEUR)':1, 'PreQTD(kEUR)':1, 'LYQTD(kEUR)':1, 'Rel_PreQTD(%)':0,'Rel_LYQTD(%)':0} )\n",
        "\n",
        "  return q_report_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMMNyYBrB7bt"
      },
      "source": [
        "f: Calculate MAT Growth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX3UmZ6NB6wu"
      },
      "outputs": [],
      "source": [
        "def calculate_growth(df):\n",
        "    '''\n",
        "    This finctions get a MAT df with QTD_Encoding and returns MAT Growth values\n",
        "    - 'Base MAT'\n",
        "    - 'Current MAT'\n",
        "    - 'MAT Growth - Current (%)'\n",
        "    - 'MAT Growth - Last Report (%)'\n",
        "    - 'MAT Growth - PrevQTD (%)'\n",
        "    '''\n",
        "\n",
        "    # Drop YTD_Encoding\n",
        "    df = df.drop(['YTD_Encoding'], axis=1)\n",
        "\n",
        "    # Create an empty DataFrame to store the growth calculations\n",
        "    growth_mat = pd.DataFrame()\n",
        "\n",
        "    # Iterate over each column in the DataFrame\n",
        "    for column in df.columns:\n",
        "        # Drop NaN values for the current column\n",
        "        column_data = df[column].dropna()\n",
        "        # Process row: Index 0\n",
        "        row_0 = column_data.iloc[0]\n",
        "        row_0 = pd.to_numeric(row_0, errors='coerce')\n",
        "\n",
        "        # Process row 3\n",
        "        row_3 = column_data.loc[df['QTD_Encoding'] == 'PreQTD'].iloc[-1]\n",
        "        row_3 = pd.to_numeric(row_3, errors='coerce')\n",
        "\n",
        "        # Process row 2\n",
        "        row_2 = column_data.iloc[-2]\n",
        "        row_2 = pd.to_numeric(row_2, errors='coerce')\n",
        "\n",
        "        # Process row 1\n",
        "        row_1 = column_data.iloc[-1]\n",
        "        row_1 = pd.to_numeric(row_1, errors='coerce')\n",
        "\n",
        "        # Calculate current MAT growth\n",
        "        growth_current_mat = 100 * (row_1 - row_0) / row_0\n",
        "\n",
        "        # Calculate last report MAT growth\n",
        "        growth_last_repo_mat = 100 * (row_2 - row_0) / row_0\n",
        "\n",
        "        # Calculate previous QTD MAT growth\n",
        "        growth_preqtd_mat = 100 * (row_3 - row_0) / row_0\n",
        "\n",
        "        # Create a Series for the column's growth calculations\n",
        "        growth_column = pd.Series(\n",
        "            {\n",
        "                'Base MAT': column_data.index[0],\n",
        "                'Current MAT': column_data.index[-1],\n",
        "                'MAT Growth - Current (%)': growth_current_mat,\n",
        "                'MAT Growth - Last Report (%)': growth_last_repo_mat,\n",
        "                'MAT Growth - PrevQTD (%)': growth_preqtd_mat,\n",
        "            }\n",
        "        ).rename(column)\n",
        "\n",
        "        # Add the column's growth calculations to the overall DataFrame\n",
        "        growth_mat = pd.concat([growth_mat, growth_column], axis=1)\n",
        "\n",
        "    # Drop the 'QTD_Encoding' column\n",
        "    growth_mat = growth_mat.drop('QTD_Encoding', axis=1)\n",
        "\n",
        "    return growth_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoclKoGEo9YR"
      },
      "source": [
        "f: Calculate QTD sales by License"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KewVqy-Z8oS"
      },
      "outputs": [],
      "source": [
        "def generate_qtd_sales_by_license(df:pd.DataFrame, product_name: str):\n",
        "\n",
        "  #limit the data for QTD sales\n",
        "  by_license_filter = df['QTD'] == 1\n",
        "  df_qtd = df.loc[by_license_filter]\n",
        "\n",
        "  #Filters\n",
        "  filter_permanent = df['EID_CODE'].str.contains('PERM')\n",
        "  filter_subscription = df['EID_CODE'].str.contains('SUB')\n",
        "  filter_ccp = df['EID_CODE'].str.contains('CCP')\n",
        "  filter_support = df['EID_CODE'].str.contains('SUPPORT')\n",
        "  filter_prorated = df['EID_CODE'].str.contains('PRO-RATED')\n",
        "  filter_updates = df['EID_CODE'].str.contains('UPDATE')\n",
        "  filter_other = df['EID_CODE'].str.contains('OTHER')\n",
        "\n",
        "  #Apply filters\n",
        "  permanent_sales = df_qtd.Sales[filter_permanent].sum()\n",
        "  permanent_qty = df_qtd.Qty[filter_permanent].sum()\n",
        "\n",
        "  subscription_sales = df_qtd.Sales[filter_subscription].sum() + df_qtd.Sales[filter_prorated].sum()\n",
        "  subscription_qty = df_qtd.Qty[filter_subscription].sum() + df_qtd.Qty[filter_prorated].sum()\n",
        "\n",
        "  ccp_sales = (df_qtd.Sales[filter_ccp].sum() + df_qtd.Sales[filter_support].sum() + df_qtd.Sales[filter_updates].sum())\n",
        "  qty_ccp = df_qtd.Qty[filter_ccp].sum() + (df_qtd.Qty[filter_support].sum() + df_qtd.Qty[filter_updates].sum())/2\n",
        "\n",
        "  other_sales = df_qtd.Sales[filter_other].sum()\n",
        "  other_qty = df_qtd.Qty[filter_other].sum()\n",
        "\n",
        "\n",
        "  #  data of lists; convert to kEUR\n",
        "  by_license_data = {'Product':[product_name, product_name],\n",
        "          'Unit':['Sales (kEUR)', 'Seat (Qty)'],\n",
        "          'Perpetual':[0.001*permanent_sales, permanent_qty],\n",
        "          'Subscription':[0.001*subscription_sales, subscription_qty],\n",
        "          'CCP':[0.001*ccp_sales, qty_ccp],\n",
        "          'Other':[0.001*other_sales, other_qty]}\n",
        "\n",
        "  by_license_df = pd.DataFrame(by_license_data)\n",
        "\n",
        "  return by_license_df.round(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XcrOH7x7HOp"
      },
      "source": [
        "f: Add missing regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HywchjJh6n1x"
      },
      "outputs": [],
      "source": [
        "def add_missing_regions(df):\n",
        "\n",
        "  #create an empty DataFrame\n",
        "  df_all_regions = pd.DataFrame(data=None, columns = df.columns)\n",
        "\n",
        "  #add all region with 0 sales value to make sure all regions are shown in the plot\n",
        "  for region in ALL_REGIONS:\n",
        "    if ~df['Region'].str.contains(region).any():\n",
        "      region_dict = {'Region': region, 'MM_YY': '00', 'Sales': 0, 'EID_CODE': 'PERM', 'QTD_Encoding': 'QTD'}\n",
        "      temporary_df = pd.DataFrame.from_dict([region_dict])\n",
        "      df_all_regions = pd.concat([df_all_regions, temporary_df], ignore_index=True)\n",
        "\n",
        "  #concat the df_region and df_all_regions\n",
        "  df_region_concat = pd.concat([df, df_all_regions], ignore_index=True)\n",
        "\n",
        "  return df_region_concat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M88vsN1n15ux"
      },
      "source": [
        "f: Add missing periods to MAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBAZgmq32BJr"
      },
      "outputs": [],
      "source": [
        "def add_missing_month_MAT(df_new, df_ref):\n",
        "  ######### TEST ########\n",
        "  '''\n",
        "  df_ref = temp_data_0\n",
        "  df_new = df_MAT_new\n",
        "  '''\n",
        "  ########################\n",
        "\n",
        "  df_merged = pd.merge(df_ref, df_new, suffixes=('_ref', '_new'), on='Date')\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df_all_new = pd.DataFrame(data=None, columns=df_ref.columns)\n",
        "\n",
        "  df_all_new['Date'] = df_merged['Date']\n",
        "  df_all_new['Sales'] = df_merged['Sales_new']\n",
        "  df_all_new['Billing'] = df_merged['Billing_new']\n",
        "  df_all_new['Period'] = df_merged['Period_ref']\n",
        "  df_all_new['Billing_MAT'] = df_merged['Billing_MAT_new']\n",
        "  df_all_new['Sales_MAT'] = df_merged['Sales_MAT_new']\n",
        "\n",
        "  # Check if 'Product_new' column is not empty before accessing the last value\n",
        "  if not df_merged['Product_new'].empty:\n",
        "      df_all_new.loc[:, 'Product'] = df_merged['Product_new'].iloc[-1]\n",
        "\n",
        "  # print(df_all_new.tail(3))\n",
        "\n",
        "  return df_all_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWdueq1xS7p4"
      },
      "source": [
        "f: Calculate Sales by Region & Quarter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdyL49bONblt"
      },
      "outputs": [],
      "source": [
        "def add_panregion_column(df):\n",
        "    df['Panregion'] = df['Region'].str.strip().map(ALL_PANREGIONS).fillna('NaN')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxNdD_gV4XeW"
      },
      "outputs": [],
      "source": [
        "def calculate_sales_by_region_and_quarter(df: pd.DataFrame, product_name: str, encoding: str):\n",
        "\n",
        "    valid_encodings = ['QTD_Encoding', 'YTD_Encoding']\n",
        "\n",
        "    if encoding not in valid_encodings:\n",
        "        raise ValueError(\"Invalid encoding. Please choose from ['QTD_Encoding', 'YTD_Encoding'].\")\n",
        "\n",
        "    # Filter based on the specified encoding\n",
        "    df = df.loc[df[encoding] != 'O']\n",
        "\n",
        "    # Aggregate based on the specified encoding\n",
        "    df_region_agg = df.groupby(['Region', 'Panregion', encoding])['Sales'].sum().reset_index()\n",
        "\n",
        "    # Sort by Sales\n",
        "    df_region_agg = df_region_agg.sort_values(['Region', encoding, 'Sales'], ascending=True)\n",
        "    df_region_agg = df_region_agg[df_region_agg[\"Region\"] != 0]\n",
        "\n",
        "    df_region_agg.insert(0, 'Product', product_name)\n",
        "\n",
        "    return df_region_agg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7blO9945TR3i"
      },
      "source": [
        "f: Calculate Sales by Region & Lic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfAMqr3bTawt"
      },
      "outputs": [],
      "source": [
        "def calculate_sales_by_region_and_lic(df:pd.DataFrame, product_name: str):\n",
        "\n",
        "  ### TEST #####\n",
        "  #df = filtered_df\n",
        "\n",
        "  ####\n",
        "\n",
        "  #filter to the QTD\n",
        "  df = df.loc[df['QTD'] == 1]\n",
        "\n",
        "  #add missing regions\n",
        "  df_all_regions = add_missing_regions(df)\n",
        "\n",
        "  #Aggregate based on 'EID_CODE'\n",
        "  df_region_agg = df_all_regions.groupby(['Region','Panregion', 'EID_GROUP'])['Sales'].agg('sum').reset_index()\n",
        "\n",
        "  #sort by Sales\n",
        "  df_region_agg = df_region_agg.sort_values(['Region', 'EID_GROUP', 'Sales'], ascending= True)\n",
        "  df_region_agg.drop(df_region_agg[df_region_agg['Region'] == 0].index, inplace = True)\n",
        "\n",
        "  #drop MISC & OTHER license types\n",
        "  df_region_agg = df_region_agg[~df_region_agg['EID_GROUP'].str.contains('Miscsallanous')]\n",
        "\n",
        "  df_region_agg.insert(0,'Product', product_name)\n",
        "\n",
        "  return df_region_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SsPsCZTLzXm"
      },
      "outputs": [],
      "source": [
        "def calculate_sales_trend_q_y_region_panregion_pivot(sales_ytd, sales_qtd, col_index):\n",
        "    # Create pivot table for YTD_Encoding\n",
        "    pivot_ytd = sales_ytd.pivot_table(values='Sales', index=col_index, columns='YTD_Encoding', aggfunc='sum')\n",
        "\n",
        "    # Create pivot table for QTD_Encoding\n",
        "    pivot_qtd = sales_qtd.pivot_table(values='Sales', index=col_index, columns='QTD_Encoding', aggfunc='sum')\n",
        "\n",
        "    # Merge the two pivot tables on the specified column index\n",
        "    merged_pivot = pd.merge(pivot_qtd, pivot_ytd, on=col_index)\n",
        "\n",
        "    #conver to kEUR\n",
        "    merged_pivot = (merged_pivot / 1000).fillna(0)\n",
        "\n",
        "    # Calculate the requested relative values\n",
        "    merged_pivot['Rel_PreQTD(%)'] = (100 * merged_pivot['QTD'] / merged_pivot['PreQTD']).fillna(0)\n",
        "    merged_pivot['Rel_LYQTD(%)'] = (100 * merged_pivot['QTD'] / merged_pivot['LYQTD']).fillna(0)\n",
        "    merged_pivot['Rel_LYTD(%)'] = (100 * merged_pivot['YTD'] / merged_pivot['LYTD']).fillna(0)\n",
        "\n",
        "\n",
        "    columns = ['QTD', 'PreQTD', 'LYQTD', 'Rel_PreQTD(%)', 'Rel_LYQTD(%)', 'YTD', 'LYTD', 'Rel_LYTD(%)']\n",
        "    return merged_pivot[columns].round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHN5gIALJ6Z"
      },
      "source": [
        "### Plot Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tvFiWq6LJuI"
      },
      "source": [
        "f: Plot QTD Sales by Region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLx4sc8mgzLd"
      },
      "outputs": [],
      "source": [
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "def plot_qtd_sales_region(df: pd.DataFrame, dir: str, product_name: str, region, display=True, pallete='tab20', show_labels=True):\n",
        "    #### TEST\n",
        "\n",
        "    #df = temp_data_1\n",
        "    #display = True\n",
        "    #pallete = 'tab20'\n",
        "\n",
        "    dir = DIRECTORY\n",
        "    product_name = PRODUCT_GROUP\n",
        "\n",
        "    ###### Exceptions ######\n",
        "    valid_regions = ['Region', 'Panregion']\n",
        "\n",
        "    if region not in valid_regions:\n",
        "        raise ValueError(\"Invalid encoding. Please choose from ['Regions', 'Panregions'].\")\n",
        "    #######################\n",
        "\n",
        "    # add missing regions\n",
        "    df = add_missing_regions(df)\n",
        "\n",
        "    plot_df = df.loc[df['QTD_Encoding'] == 'QTD'].copy()\n",
        "\n",
        "    # Aggregate sum of sales by region\n",
        "    plot_df = plot_df.groupby(region).agg({'Sales':'sum'}).reset_index()\n",
        "\n",
        "    plot_df.sort_values('Sales', ascending=False, inplace=True)\n",
        "\n",
        "    # Calculate total sales\n",
        "    total_sales = plot_df['Sales'].sum()\n",
        "\n",
        "    ### SETTINGS\n",
        "\n",
        "    # Turn interactive plotting off\n",
        "    if not display:\n",
        "        plt.ioff()\n",
        "\n",
        "    # Plot & font size\n",
        "    plt.figure(figsize=[11, 5])\n",
        "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
        "\n",
        "    #### DATA ###\n",
        "    # Get Sales row of the dataframe\n",
        "\n",
        "    # Plot values\n",
        "    plot_labels = list(plot_df[region])\n",
        "    plot_sizes = list(plot_df['Sales'])\n",
        "    bar_plot_labels = [f'{s / total_sales * 100:0.1f}%' if show_labels else '' for l, s in zip(plot_labels, plot_sizes)]\n",
        "\n",
        "    #### PLOT ####\n",
        "    # Title\n",
        "    plot_title_by_region = str(product_name) + ' - QTD Sales by ' + region + ' (' + PROCESS_MONTH + ')'\n",
        "\n",
        "    # Labels\n",
        "    plt.title(plot_title_by_region)\n",
        "\n",
        "    numOfItemx = len(bar_plot_labels)\n",
        "\n",
        "    # Color\n",
        "    color = []\n",
        "    for i in range(numOfItemx):\n",
        "        color.append(gradient_color_picker(i, numOfItemx, pallete))\n",
        "\n",
        "    # Bar plot definition\n",
        "    bars = plt.bar(plot_labels, plot_sizes, color=color, edgecolor='black', linewidth=0.4)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Adding percentages on top of the bars if show_labels is True\n",
        "    for i, bar in enumerate(bars):\n",
        "        if show_labels:\n",
        "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), bar_plot_labels[i], ha='center', va='bottom', fontsize=FONT_SIZE)\n",
        "\n",
        "    # Y-axis thousand comma separator\n",
        "    formatter = FuncFormatter(lambda x, _: f'{x:,.0f}')\n",
        "    plt.gca().yaxis.set_major_formatter(formatter)\n",
        "\n",
        "\n",
        "\n",
        "    # Legend\n",
        "    if region == 'Panregion':\n",
        "        legend_labels = list(plot_df['Panregion'])\n",
        "        plt.legend(bars, legend_labels)\n",
        "\n",
        "    # ...\n",
        "\n",
        "    #### STORE ####\n",
        "    # Save as png\n",
        "    file_address = dir + plot_title_by_region\n",
        "    plt.savefig(file_address, bbox_inches='tight')\n",
        "\n",
        "    if not display:\n",
        "        plt.close()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38tvMo2t1qrq"
      },
      "source": [
        "f: Plot (Pie): Q Sales by License"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tprzi07A8Ca"
      },
      "outputs": [],
      "source": [
        "def plot_qtd_sales_license(df: pd.DataFrame, dir: str, product_name: str, display=False):\n",
        "    import matplotlib.ticker as ticker\n",
        "\n",
        "    #### TEST\n",
        "\n",
        "    '''\n",
        "    df = qtd_sales_license_seat\n",
        "    dir = DIRECTORY\n",
        "    display = True\n",
        "    product_name = 'ddsdsdsd\n",
        "    '''\n",
        "\n",
        "    ####\n",
        "\n",
        "    df = df.loc[df['Product']==product_name]\n",
        "\n",
        "\n",
        "    # Define a function to multiply numeric values by 1000\n",
        "    def multiply_by_1000(x):\n",
        "        if isinstance(x, (int, float)):\n",
        "            return x * 1000\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    # Apply the function to all numeric values of the dataframe\n",
        "    df = df.applymap(multiply_by_1000)\n",
        "\n",
        "    # SETTINGS\n",
        "    # Turn interactive plotting off\n",
        "    if not display:\n",
        "        plt.ioff()\n",
        "\n",
        "    # Set color\n",
        "    colors = COLOR_SET_google\n",
        "\n",
        "    # Plot and font size\n",
        "    plt.figure(figsize=[7, 5])\n",
        "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
        "\n",
        "    # DATA\n",
        "    # Get Sales row of the dataframe\n",
        "    df_plot = df.drop(columns=['Product', 'Unit']).sort_index(axis=1)\n",
        "    df_plot = df_plot.iloc[0]\n",
        "\n",
        "    # Plot values\n",
        "    bar_plot_labels = list(df_plot.keys())  # [Perpetual, Subscription, CCP, Other]\n",
        "    bar_plot_x = list(df_plot)\n",
        "\n",
        "    # Sort the bar plot labels according to 'EID_GROUP' values\n",
        "    sort_order = ['CCP', 'Subscription', 'Perpetual', 'Other']\n",
        "    bar_plot_labels, bar_plot_x = zip(*sorted(zip(bar_plot_labels, bar_plot_x), key=lambda x: sort_order.index(x[0])))\n",
        "\n",
        "    # Calculate the total sum of the values\n",
        "    total_sum = sum(bar_plot_x)\n",
        "\n",
        "    # PLOT\n",
        "    # Title\n",
        "    by_license_plot_title = product_name + ' - QTD Sales by License' + ' (' + PROCESS_MONTH +  ')'\n",
        "    plt.title(by_license_plot_title)\n",
        "\n",
        "    # Bar plot definition\n",
        "    bars = plt.bar(bar_plot_labels, bar_plot_x, color=colors, edgecolor='black', linewidth=0.4)\n",
        "\n",
        "\n",
        "    # x-axis label\n",
        "    plt.xlabel('License Type')\n",
        "\n",
        "    # Add percentage of all values to the bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        percentage = (height / total_sum) * 100\n",
        "        plt.gca().text(bar.get_x() + bar.get_width() / 2, height, '{:.1f}%'.format(percentage),\n",
        "                       ha='center', va='bottom', fontsize=FONT_SIZE)\n",
        "\n",
        "    # y-axis label with thousand separator\n",
        "    plt.ylabel('Sales (EUR)')\n",
        "    formatter = ticker.StrMethodFormatter('{x:,.0f}')\n",
        "    plt.gca().yaxis.set_major_formatter(formatter)\n",
        "\n",
        "    plt.xticks(rotation=0, ha='center')\n",
        "    plt.yticks(rotation=0, ha='right')\n",
        "    # plt.legend(loc='upper left')\n",
        "\n",
        "    # Set graphics\n",
        "    plt.grid(linestyle='--', axis='y')\n",
        "\n",
        "    # STORE\n",
        "    # Save as png\n",
        "    plt.savefig(dir + '/' + by_license_plot_title, bbox_inches='tight')\n",
        "\n",
        "    if not display:\n",
        "        plt.close()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Um36a0mrKWR"
      },
      "source": [
        "f: Plot (Bar): Sales Trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L-1VUXwMlEZ"
      },
      "outputs": [],
      "source": [
        "def plot_q_sales_trend (df:pd.DataFrame, dir, product_name:str, display = True):\n",
        "  ######## TEST ########\n",
        "  '''\n",
        "  df = q_report_df\n",
        "  display = True\n",
        "  dir = DIRECTORY\n",
        "  product_name = 'SSSTHHHHH'\n",
        "  '''\n",
        "  #####################\n",
        "\n",
        "  # Turn interactive plotting off\n",
        "  if not display:\n",
        "    plt.ioff()\n",
        "\n",
        "\n",
        "  #Transform the data\n",
        "  df = df.rename(columns={'QTD(kEUR)': 'QTD', 'PreQTD(kEUR)': 'PreQTD', 'LYQTD(kEUR)': 'LYQTD'})\n",
        "  df = df.drop(['Rel_PreQTD(%)', 'Rel_LYQTD(%)'], axis = 1)\n",
        "\n",
        "  plot_df = pd.melt(df, id_vars=['Product'], value_vars=['QTD', 'PreQTD', 'LYQTD'], var_name='QTD_Encoding', value_name='Sales')\n",
        "  plot_df['Sales'] = plot_df['Sales']*1000\n",
        "\n",
        "  hue_order = ['LYQTD', 'PreQTD', 'QTD']\n",
        "\n",
        "  #set the lenth of figure based on the number of products\n",
        "  num_of_products = len(plot_df['Product'].unique())\n",
        "  fig_len = 1 + num_of_products * 2\n",
        "\n",
        "  #agg_function options\n",
        "  add_plot_title_phrase = ' Q-Q'\n",
        "  sns_colour = sns.set_palette(COLOR_SET_google)\n",
        "  linewidth = 0.4\n",
        "  saturation= 0.9\n",
        "\n",
        "\n",
        "  #plot & font size\n",
        "  plt.figure(figsize=[fig_len,6])\n",
        "  plt.rcParams[\"font.size\"] = FONT_SIZE\n",
        "\n",
        "  #barchart definition\n",
        "  ax = sns.barplot(x='Product', y='Sales', hue= 'QTD_Encoding',\n",
        "                   saturation = saturation,  palette=sns_colour,\n",
        "                   edgecolor = 'black', linewidth = linewidth,\n",
        "                   hue_order = hue_order,\n",
        "                   errorbar = None, data = plot_df)\n",
        "\n",
        "  #invert x axis to show larget sales at the left\n",
        "  #ax.invert_xaxis()\n",
        "\n",
        "  #Title\n",
        "  plot_title = product_name +': Q-Q Short Term Trends' + ' (' + PROCESS_MONTH +  ')'\n",
        "\n",
        "  #set labels\n",
        "  plt.ylabel(\"Sales (EUR)\")\n",
        "  plt.title(plot_title)\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.yticks(rotation=0, ha='right')\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "  #set graphics\n",
        "  plt.grid(linestyle='--', axis='y')\n",
        "\n",
        "  #adding commas to thousands, matplotlib, python\n",
        "  ax.get_yaxis().set_major_formatter(tick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "\n",
        "  #Save & show\n",
        "  plt.savefig(dir + '/' +  plot_title, bbox_inches = 'tight')\n",
        "\n",
        "  if not display:\n",
        "    plt.close()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSH-pRj5WU8a"
      },
      "source": [
        "f: Plot (Bar): Sales by Region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64I9G-tx-XG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBDSAAcfx-pb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlGnLGHpx-mt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2trnpyuxWZuL"
      },
      "outputs": [],
      "source": [
        "def plot_sales_by_region(df: pd.DataFrame, product_name: str, dir: str, display=True, region = 'region_select', agg_function='agg_func_select'):\n",
        "    ####### TEST ###########\n",
        "    #df = temp_data_1\n",
        "    #product_name = PRODUCT_GROUP\n",
        "    #dir = DIRECTORY\n",
        "    #display = True\n",
        "    #agg_function = 'QTD_Encoding'\n",
        "    #########################\n",
        "\n",
        "    #add missing regions\n",
        "    df = add_missing_regions(df)\n",
        "\n",
        "    # Turn interactive plotting off\n",
        "    if not display:\n",
        "        plt.ioff()\n",
        "\n",
        "    # agg_function options\n",
        "    agg_func_select = ['QTD_Encoding', 'YTD_Encoding', 'EID_GROUP']\n",
        "    region_select = ['Region', 'Panregion']\n",
        "\n",
        "    if agg_function == 'QTD_Encoding':  # when QTD is selected\n",
        "        add_plot_title_phrase = ' Q-Q'\n",
        "        sns_colour = sns.set_palette(COLOR_SET_google)\n",
        "        linewidth = 0.4\n",
        "\n",
        "    elif agg_function == 'YTD_Encoding':  # when YTD is selected\n",
        "        add_plot_title_phrase = ' Y-Y'\n",
        "        sns_colour = sns.set_palette(COLOR_SET_google)\n",
        "        linewidth = 0.4\n",
        "\n",
        "    else:  # when EID_CODE is selected\n",
        "        add_plot_title_phrase = ' and License'\n",
        "        sns_colour = sns.color_palette(COLOR_SET_google)\n",
        "        linewidth = 0.2\n",
        "\n",
        "        # Drop rows with 'Miscellaneous' in 'EID_GROUP' column\n",
        "        df = df[df['EID_GROUP'] != 'Miscellaneous'].copy()\n",
        "\n",
        "        # Sort the data by 'Regions' and 'EID_GROUP'\n",
        "        sort_order = ['CCP', 'Subscription', 'Perpetual', 'Other']\n",
        "        df['EID_GROUP'] = pd.Categorical(df['EID_GROUP'], categories=sort_order, ordered=True)\n",
        "        df.sort_values(by=[region, 'EID_GROUP'], inplace=True)\n",
        "\n",
        "    # Aggregate sum of sales by region and agg_function\n",
        "    df = df.groupby([region, agg_function]).agg({'Sales':'sum'}).reset_index()\n",
        "\n",
        "    # plot & font size\n",
        "    plt.rcParams[\"font.size\"] = FONT_SIZE\n",
        "\n",
        "    if region == 'Panregion':\n",
        "      plt.figure(figsize=[12, 6])\n",
        "    else:\n",
        "      plt.figure(figsize=[20, 6])\n",
        "\n",
        "    # barchart definition\n",
        "    ax = sns.barplot(x=region, y='Sales', hue=agg_function,\n",
        "                     saturation=0.9, palette=sns_colour, edgecolor='black',\n",
        "                     linewidth=linewidth, errorbar=None, data=df)\n",
        "\n",
        "    # Title\n",
        "    by_region_plot_title = product_name + ': Sales by ' +  region + add_plot_title_phrase + ' (' + PROCESS_MONTH +  ')'\n",
        "\n",
        "    # set labels\n",
        "    plt.ylabel(\"Sales (EUR)\")\n",
        "    plt.title(by_region_plot_title)\n",
        "    plt.xticks(rotation=0, ha='center')\n",
        "    plt.yticks(rotation=0, ha='right')\n",
        "\n",
        "    # Set legend location\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    # set graphics\n",
        "    plt.grid(linestyle='--', axis='y')\n",
        "\n",
        "    # adding commas to thousands, matplotlib, python\n",
        "    ax.get_yaxis().set_major_formatter(tick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "\n",
        "    # Save & show\n",
        "    plt.savefig(dir + '/' + by_region_plot_title, bbox_inches='tight')\n",
        "\n",
        "    if not display:\n",
        "        plt.close()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5MRgoDAqcm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_UDkgOU93Fg"
      },
      "source": [
        "f: Plot (Line): MAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l6sZtt9Dt82"
      },
      "outputs": [],
      "source": [
        "def plot_MAT(df:pd.DataFrame, dir:str, label = '', display=True, startIndex = 0, pallete = 'PALLETE'):\n",
        "  ### TEST ###\n",
        "  '''\n",
        "  df = df_MAT\n",
        "  display = True\n",
        "  dir = DIRECTORY\n",
        "  startIndex = 0\n",
        "  product_name = 'XXXXXX'\n",
        "  pallete = 'viridis'\n",
        "  '''\n",
        "  ########################\n",
        "\n",
        "  product_name = df_MAT.iloc[0]['Product']\n",
        "\n",
        "  # Turn interactive plotting off\n",
        "  if not display:\n",
        "    plt.ioff()\n",
        " #Get all the products in the df\n",
        "  my_products = df['Product'].unique()\n",
        "  #Use the first product (Product Group)\n",
        "  plot_df = df.loc[df.Product == my_products[startIndex]]\n",
        "\n",
        "  #plot & font size\n",
        "  fig, ax = plt.subplots(figsize=[15,6])\n",
        "  plt.rcParams[\"font.size\"] = FONT_SIZE\n",
        "\n",
        "  #plot title\n",
        "  plot_title_mat = product_name +': Worldwide MAT' + label + ' (' + PROCESS_MONTH +  ')'\n",
        "\n",
        "\n",
        "  #y and y axes ranges\n",
        "  y_max = 1.1 * max (plot_df['Billing_MAT'].max(),plot_df['Sales_MAT'].max())\n",
        "  x_max = plot_df['Billing_MAT'].count()\n",
        "\n",
        "  #Plot grid, title, and labels\n",
        "  plt.ylabel('EUR')\n",
        "  plt.ylim(0,y_max)\n",
        "  plt.xlim(1,x_max+1)\n",
        "  plt.title(plot_title_mat)\n",
        "\n",
        "\n",
        "  #Add ticks\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.yticks(rotation=0, ha='right')\n",
        "\n",
        "  #Set grid\n",
        "  plt.grid(linestyle='dotted', axis='y')\n",
        "  plt.grid(linestyle='dotted', axis='x')\n",
        "\n",
        "  #Add thousands comma\n",
        "  current_values = plt.gca().get_yticks().tolist()\n",
        "  plt.gca().set_yticks(current_values)\n",
        "  plt.gca().set_yticklabels(['{:,.0f}'.format(x) for x in current_values])\n",
        "\n",
        "\n",
        "  flag = False\n",
        "  i = 0\n",
        "  for item in my_products[startIndex:]:\n",
        "    #print(item)\n",
        "    plot_df = df.loc[df.Product == item]\n",
        "    x = plot_df['Period'].tolist()\n",
        "\n",
        "    if i == 0 and startIndex == 0:\n",
        "      new_color = gradient_color_picker(i,len(my_products), pallete)\n",
        "      label = str(item) + ': Billing_MAT'\n",
        "      ax.plot(x, plot_df['Billing_MAT'], color = new_color,  label= label)\n",
        "\n",
        "    i = i + 1\n",
        "    new_color = gradient_color_picker(i,len(my_products), pallete)\n",
        "    label = str(item) +': Sales_MAT'\n",
        "    ax.plot(x, plot_df['Sales_MAT'], color = new_color, label= label)\n",
        "\n",
        "    #Add legend\n",
        "    legend = ax.legend(loc='upper left', fontsize='x-small')\n",
        "\n",
        "  #### STORE ####\n",
        "  #Save as png\n",
        "  plt.savefig(dir + '/' + plot_title_mat, bbox_inches = 'tight')\n",
        "\n",
        "  if not display:\n",
        "    plt.close()\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNWtQIEkLjIh"
      },
      "source": [
        "### Reshape Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJiMq5_iLrKs"
      },
      "outputs": [],
      "source": [
        "## reshape MAT data for Excel\n",
        "def reshape_excel_plot_MAT(df_MAT):\n",
        "    '''\n",
        "    This function reshapes the MAT WW dataframe for Excel plotting.\n",
        "    '''\n",
        "    column_names = df_MAT['Product'].unique()\n",
        "\n",
        "    # Initialize the DataFrame with the first product\n",
        "    df_plot_temp = df_MAT.loc[df_MAT['Product'] == column_names[0]]\n",
        "    df_MAT_Excel_Plot = df_plot_temp[['Date', 'Period', 'Billing_MAT', 'QTD_Encoding', 'YTD_Encoding']].copy()\n",
        "    df_MAT_Excel_Plot.rename(columns={'Billing_MAT': str(column_names[0]) + ': Billing_MAT'}, inplace=True)\n",
        "\n",
        "    # Merge data for each product into the main DataFrame\n",
        "    for item in column_names:\n",
        "        df_plot_temp = df_MAT.loc[df_MAT['Product'] == item]\n",
        "        df_plot_temp = df_plot_temp[['Date', 'Sales_MAT']].copy()\n",
        "        df_plot_temp.rename(columns={'Sales_MAT': (str(item) + ': Sales_MAT')}, inplace=True)\n",
        "        df_MAT_Excel_Plot = df_MAT_Excel_Plot.merge(df_plot_temp, on='Date')\n",
        "        df_MAT_Excel_Plot.set_index('Date', inplace=True)\n",
        "\n",
        "    # Set \"Period\" as the index\n",
        "    df_MAT_Excel_Plot = df_MAT_Excel_Plot.loc[~df_MAT_Excel_Plot['Period'].isnull()].copy()\n",
        "    df_MAT_Excel_Plot.set_index('Period', inplace=True)\n",
        "\n",
        "\n",
        "    # Move 'QTD_Encoding', 'YTD_Encoding' to the end\n",
        "    columns_to_move_names = ['QTD_Encoding', 'YTD_Encoding']\n",
        "    # Step 2: Create a new dataframe without the columns to be moved\n",
        "    new_df = df_MAT_Excel_Plot.drop(columns_to_move_names, axis=1)\n",
        "\n",
        "    # Step 3: Create a dataframe with only the columns to be moved\n",
        "    columns_to_move = df_MAT_Excel_Plot[columns_to_move_names]\n",
        "\n",
        "    # Step 4: Concatenate the new dataframe with the columns to be moved\n",
        "    concatenated_df = pd.concat([new_df, columns_to_move], axis=1)\n",
        "\n",
        "    return concatenated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QcSZ5VWL3Lo"
      },
      "outputs": [],
      "source": [
        "## Reshape sales by resgion for Excel\n",
        "def reshape_sales_by_region(sales_by_region_and_lic):\n",
        "  '''This function gets the sales_by_region_and_lic and reshape it to make Excel plot ready'''\n",
        "\n",
        "  region_names = sales_by_region_and_lic['Region'].unique()\n",
        "  df_Excel = pd.DataFrame(index=region_names)\n",
        "\n",
        "  #Make a copy of region indexes\n",
        "  df_region_names=df_Excel.copy()\n",
        "\n",
        "  #get the name of all products\n",
        "  names = sales_by_region_and_lic['Product'].unique()\n",
        "\n",
        "  for item in names:\n",
        "    #filter to the first product\n",
        "    df_temp = sales_by_region_and_lic.loc[sales_by_region_and_lic['Product'] == item]\n",
        "    df_temp = df_temp.groupby(by = ['Region'])['Sales'].agg(['sum'])\n",
        "    df_temp.sort_values('sum', ascending = False, inplace = True)\n",
        "\n",
        "    #Reindex df_temp to add Regions with no sales\n",
        "    df_temp = df_temp.reindex(df_region_names.index, fill_value=0)\n",
        "\n",
        "    df_temp.rename(columns = {'sum': str(item)}, inplace = True )\n",
        "    df_Excel = pd.merge(df_Excel, df_temp, left_index = True, right_index = True)\n",
        "\n",
        "  df_Excel.sort_index(ascending = True, inplace = True)\n",
        "\n",
        "  return df_Excel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GUplF1eWHIj"
      },
      "source": [
        "## --- Data ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edwtf1fhupiz"
      },
      "source": [
        "Upload Datasheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeeQ5qkwuvWO"
      },
      "outputs": [],
      "source": [
        "# Upload -byarticle-byregion Excel file\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcBVJyL0uozs"
      },
      "outputs": [],
      "source": [
        "file_upload = next(iter(uploaded)) #get the uploaded file\n",
        "df_upload = pd.read_excel(io.BytesIO(uploaded[file_upload])) #cast the excel file to a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UnAUDq2DeBX"
      },
      "outputs": [],
      "source": [
        "print(f'The uploaded Excel file has the size of {df_upload.shape}\\n')\n",
        "df_upload.head() #print first 5 rows of df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ji-5a6gC8h"
      },
      "outputs": [],
      "source": [
        "def keep_columns_by_index(dataframe, start_index, end_index):\n",
        "    \"\"\"\n",
        "    Keep columns in the specified index range and drop the others.\n",
        "\n",
        "    Parameters:\n",
        "        dataframe (pd.DataFrame): The DataFrame you want to modify.\n",
        "        start_index (int): The starting column index to keep (inclusive).\n",
        "        end_index (int): The ending column index to keep (inclusive).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The modified DataFrame with only the specified columns.\n",
        "    \"\"\"\n",
        "    if not isinstance(dataframe, pd.DataFrame):\n",
        "        raise ValueError(\"Input must be a Pandas DataFrame\")\n",
        "\n",
        "    if start_index < 0 or end_index < 0:\n",
        "        raise ValueError(\"Start and end indices must be non-negative\")\n",
        "\n",
        "    if start_index > end_index or start_index >= len(dataframe.columns) or end_index >= len(dataframe.columns):\n",
        "        raise ValueError(\"Invalid start or end index\")\n",
        "\n",
        "    # Get the list of column names to keep\n",
        "    columns_to_keep = dataframe.columns[start_index:end_index + 1]\n",
        "\n",
        "    # Keep only the specified columns and drop the rest\n",
        "    dataframe_filtered = dataframe[columns_to_keep]\n",
        "\n",
        "    return dataframe_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74Aj_uTvgGfB"
      },
      "outputs": [],
      "source": [
        "df_drop = keep_columns_by_index(df_upload, 0, 7)\n",
        "df_drop.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViixYdppvnfI"
      },
      "source": [
        " **IMPORTANT:** Make sure the column names and data math; otherwise, the data should be re-exported or the **Pre-processing: Renaming & Cleaning** section should be modified.\n",
        "```\n",
        "- Material\n",
        "- Material Name\n",
        "- Country (Addr. Ship-To)\n",
        "- Country (Addr. Ship-To)\n",
        "- Fiscal year/period\n",
        "- 4.2:Billing exFr GC\n",
        "- 4.4 Billing qty\n",
        "- 5.2:Sales exFr GC\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpkW9TsOWE19"
      },
      "source": [
        "Renaming & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFrt_BpYU7Jf"
      },
      "outputs": [],
      "source": [
        "#Set the Headers\n",
        "column_header =['PID', 'License', 'Region_ID', 'Region', 'MM_YY', 'Billing', 'Qty', 'Sales']\n",
        "df_drop.columns = column_header\n",
        "\n",
        "#Make a copy of df_read\n",
        "df = cleanup_and_rename(df_drop, 1)\n",
        "#see the header\n",
        "print(f'\\nThe size of dataframe is {df.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV16DN9iDLkn"
      },
      "outputs": [],
      "source": [
        "PROCESS_MONTH = df['Date'].max().strftime('%Y-%m')\n",
        "print(PROCESS_MONTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3itHj3UjBhCd"
      },
      "source": [
        "Add missing Date, PID, Region to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8vnTqISBhpu"
      },
      "outputs": [],
      "source": [
        "select_list = ['Date', 'PID', 'Region']\n",
        "# Create a new DataFrame with all possible combinations of the columns in select_list\n",
        "all_combinations = pd.MultiIndex.from_product([df[col].unique() for col in select_list],\n",
        "                                              names=select_list).to_frame(index=False)\n",
        "\n",
        "# Merge the new DataFrame with the original one\n",
        "new_df = pd.merge(all_combinations, df, on=select_list, how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxXeEn1iPyk4"
      },
      "outputs": [],
      "source": [
        "df = new_df.fillna(0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHsmmh5zByZj"
      },
      "outputs": [],
      "source": [
        "#see the header\n",
        "print(f'\\nThe size of dataframe is {new_df.shape}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsq-Fg-Kh8Nf"
      },
      "source": [
        "Read product license info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp7H611GYutQ"
      },
      "outputs": [],
      "source": [
        "#url address for gs workbook\n",
        "workbook_url = 'https://docs.google.com/spreadsheets/d/1Gbwg4edyMHps1QQQmm_6AiR8IDUN0A_6kEtZ0pOWXz8/edit#gid=1839828940'\n",
        "\n",
        "#Read product categories and names inot a DataFrame\n",
        "product_wb = read_gs_by_url(workbook_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj3gKhBrZXt9"
      },
      "outputs": [],
      "source": [
        "#Read dataframes from gs workbook & and clean up the dataframes\n",
        "df_all_lic = workbook_to_dataframe(product_wb, 'All_Licenses')\n",
        "df_product_groups = workbook_to_dataframe(product_wb, 'Product_Groups')\n",
        "\n",
        "df_all_lic = dataframe_header(df_all_lic)\n",
        "df_product_groups = dataframe_header(df_product_groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLxzK31GawZL"
      },
      "outputs": [],
      "source": [
        "df_all_lic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu05h3Hy8b-k"
      },
      "source": [
        "##Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-G78Vw5uaWO"
      },
      "source": [
        "Drop duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KnFRdHVuZ5B"
      },
      "outputs": [],
      "source": [
        "print(f'The size of dataframe is {df_all_lic.shape}\\n')\n",
        "df_all_lic = df_all_lic.drop_duplicates(subset='PID', keep=\"first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exj2NtiVu9qz"
      },
      "source": [
        "Merge product & sales dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXOk17kEj7U-"
      },
      "outputs": [],
      "source": [
        "#change PID type to int\n",
        "df_all_lic['PID'] = df_all_lic['PID'].astype(int)\n",
        "df['PID'] = df['PID'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-uQlnlyu8vc"
      },
      "outputs": [],
      "source": [
        "#perfrom a Left JOIN on the sales table and product table\n",
        "merged_df = pd.merge(df, df_all_lic, on = 'PID', how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKxEkBqAeo-B"
      },
      "outputs": [],
      "source": [
        "merged_df['License'] = merged_df['LICENSE']\n",
        "merged_df = merged_df.drop('LICENSE', axis =1 )\n",
        "merged_df = merged_df[merged_df.Region != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnaqHFImhEVz"
      },
      "outputs": [],
      "source": [
        "print(f'The size of dataframe is {merged_df.shape}\\n')\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr8R5MpYeVti"
      },
      "outputs": [],
      "source": [
        "# Create a boolean mask for the rows with \"PRO-RATED\"\n",
        "mask = merged_df['EID_CODE'] == \"PRO-RATED\"\n",
        "\n",
        "# Use loc to update the \"PRO-RATED\" values from days to seats\n",
        "merged_df.loc[mask, 'Qty'] = merged_df.loc[mask, 'Qty'] /365\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.Date.max()"
      ],
      "metadata": {
        "id": "yiCnNNQqBaxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKL8iP3bXlMW"
      },
      "source": [
        "Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv7SwXYIXkh5"
      },
      "outputs": [],
      "source": [
        "#Add YTD, LYTD, QTD, LYQTD, PreQTD to df\n",
        "df_encoded = encode_year_quarter(merged_df)\n",
        "\n",
        "#Add Q Y Encoding based on QTD & YTD columns\n",
        "df_encoded = add_encoding_columns(df_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7q9D3N-qXTX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LucZCZ8yl1kw"
      },
      "outputs": [],
      "source": [
        "# Add Panregion column\n",
        "df_encoded.insert(4, 'Panregion', df_encoded['Region'].str.strip().map(ALL_PANREGIONS).fillna('NaN'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K919FlvkiEYq"
      },
      "source": [
        "## --- Select Product ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qyKiq3w09V"
      },
      "outputs": [],
      "source": [
        "#Define productIdx as -1 before starting (DON'T RETURN TO THIS LINE)\n",
        "productIdx = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wKGN3uuggi1"
      },
      "source": [
        "User input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB82IXRDZNXB"
      },
      "outputs": [],
      "source": [
        "# Use the previous `ProdcyIdx`. This will help the user to know which product they should next\n",
        "print('Suggested Index:', productIdx + 1, '\\n')\n",
        "\n",
        "#Get user user input\n",
        "group_dict = column_to_dict(df_product_groups.columns)\n",
        "productIdx = get_user_input_int(0, len(group_dict)-1)\n",
        "\n",
        "PRODUCT_GROUP = group_dict[productIdx]\n",
        "group_dct = column_to_dict(df_product_groups[PRODUCT_GROUP], output = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XR4lwI1OGjv"
      },
      "source": [
        "## Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKOzjJYmoQ0s"
      },
      "outputs": [],
      "source": [
        "df_encoded['Date'].max().strftime('%Y-%m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqWuKPP9wsiP"
      },
      "outputs": [],
      "source": [
        "#Processing message\n",
        "print(f'Processing Product Group: {productIdx}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RpoGjFVfQEZ"
      },
      "source": [
        "Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ0QnS1F5t9o"
      },
      "outputs": [],
      "source": [
        "#Set working directory\n",
        "DIRECTORY = '/content/QBR_REPORTS/'+ str(productIdx) + '_'+ PRODUCT_GROUP + '/'\n",
        "#create directory\n",
        "if os.path.exists(DIRECTORY):\n",
        "    shutil.rmtree(DIRECTORY)\n",
        "os.makedirs(DIRECTORY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUsUIxnCfSpB"
      },
      "source": [
        "Total: All Product in Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqGgrsCdjHa-"
      },
      "outputs": [],
      "source": [
        "#========== Filter_ALL: by Articles =========#\n",
        "#filter dataframe with boolean filter\n",
        "boolean_filter_pid = df_encoded[\"CD\"].str.contains(PRODUCT_GROUP) | df_encoded[\"SUBGROUP\"].str.contains(PRODUCT_GROUP)\n",
        "filtered_df = df_encoded[boolean_filter_pid]\n",
        "raw_data = filtered_df.drop(['QTD_Encoding', 'YTD_Encoding'], axis = 1).copy()\n",
        "print(f'Number of \"{PRODUCT_GROUP}\" transactions found: {filtered_df.shape[0]}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usx_vLo0hcC-"
      },
      "outputs": [],
      "source": [
        "raw_data.sort_values(by = 'Date', ascending= True, inplace = True)\n",
        "raw_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2g045oudh-9"
      },
      "outputs": [],
      "source": [
        "#Write raw data to excel\n",
        "with pd.ExcelWriter(DIRECTORY + '/raw_data_' + PRODUCT_GROUP + '.xlsx', engine='xlsxwriter') as writer:\n",
        "  raw_data.to_excel(writer, sheet_name='raw_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdGRW-7v_de1"
      },
      "outputs": [],
      "source": [
        "#===========  Calculate_ALL: MAT ============#\n",
        "#Calcualte the MAT for PRODUCT_GROUP\n",
        "df_MAT = calculate_mat(filtered_df, PRODUCT_GROUP)\n",
        "temp_data_0 = df_MAT #temp data for plot\n",
        "\n",
        "#Calcualte the MAT for GROUPs & Regions\n",
        "if productIdx == 0:\n",
        "  df_MAT_group = calculate_mat_group(filtered_df, 'GROUP')\n",
        "\n",
        "#Calcualte the MAT for Regions\n",
        "df_MAT_region = calculate_mat_group(filtered_df, 'Region')\n",
        "df_MAT_panregion = calculate_mat_group(filtered_df, 'Panregion')\n",
        "\n",
        "#========  Calculate_ALL: Sales Trend ========#\n",
        "#Calculate q repoort df for PRODUCT_GROUP\n",
        "q_report_df = generate_q_sales_report(filtered_df, PRODUCT_GROUP)\n",
        "\n",
        "\n",
        "#========  Calculate ALL: QTD Sales by Product ========#\n",
        "#Calculate QTD Sales by PRODUCT_GROUP\n",
        "qtd_sales_license_seat = generate_qtd_sales_by_license(filtered_df, PRODUCT_GROUP)\n",
        "\n",
        "#==========  Calculate ALL: Sales by Region =========#\n",
        "#Calculate Sales by Region and Quarter\n",
        "sales_by_region_and_q = calculate_sales_by_region_and_quarter(filtered_df, PRODUCT_GROUP, 'QTD_Encoding')\n",
        "temp_data_1 = sales_by_region_and_q #temp data for plot\n",
        "\n",
        "#Calculate Sales by Region and License\n",
        "sales_by_region_and_lic = calculate_sales_by_region_and_lic(filtered_df, PRODUCT_GROUP)\n",
        "temp_data_2 = sales_by_region_and_lic #temp data for plot\n",
        "\n",
        "#Calculate Sales by Region and YTD\n",
        "sales_by_region_and_y = calculate_sales_by_region_and_quarter(filtered_df, PRODUCT_GROUP, 'YTD_Encoding')\n",
        "temp_data_3 = sales_by_region_and_y #temp data for plot\n",
        "\n",
        "\n",
        "#Calculate Sales Trends for Region and Panregions for Q & Y (ALL ONLY)\n",
        "#set empty then try to calcluate\n",
        "sales_trend_q_y_region_all = pd.DataFrame()\n",
        "sales_trend_q_y_panregion_all = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "  sales_trend_q_y_region_all = calculate_sales_trend_q_y_region_panregion_pivot(sales_by_region_and_y, sales_by_region_and_q, 'Region')\n",
        "except:\n",
        "  pass #do nothing\n",
        "try:\n",
        "  sales_trend_q_y_panregion_all = calculate_sales_trend_q_y_region_panregion_pivot(sales_by_region_and_y, sales_by_region_and_q, 'Panregion')\n",
        "except:\n",
        "  pass #do nothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMfVhn2mfbO1"
      },
      "source": [
        "Each Product in Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnCbkhvaVqbR"
      },
      "outputs": [],
      "source": [
        "#If there are more than one product in the group\n",
        "if len(group_dct.values()) > 1:\n",
        "\n",
        "  #For product in the group, except the first one\n",
        "  for item in list(group_dct.values()):\n",
        "    print(item)\n",
        "\n",
        "    #========== Filter: by Articles =========#\n",
        "    #Filter df_encoded by product article keywords\n",
        "    boolean_filter_pid = df_encoded[\"CD\"].str.contains(item) | df_encoded[\"SUBGROUP\"].str.contains(item)\n",
        "    filtered_df = df_encoded[boolean_filter_pid]\n",
        "\n",
        "\n",
        "    #===========  Calculate: MAT ============#\n",
        "    #Calculate MAT for the new filtered df\n",
        "    df_MAT_new = calculate_mat(filtered_df, item)\n",
        "    df_MAT_all_periods = add_missing_month_MAT(df_MAT_new, temp_data_0)\n",
        "    #Append the new MAT dataframe to the end of df_MAT\n",
        "    df_MAT = pd.concat([df_MAT, df_MAT_all_periods], axis=0)\n",
        "\n",
        "\n",
        "    #========  Calculate: Sales Trend ========#\n",
        "    #Calculate q repoort df for the new filtered df\n",
        "    q_report_df_new = generate_q_sales_report(filtered_df, item)\n",
        "    #Append the new q repoort df dataframe to the q repoort df\n",
        "    q_report_df = pd.concat([q_report_df, q_report_df_new], axis=0)\n",
        "\n",
        "    #========  Calculate: QTD Sales by Product ========#\n",
        "    #Calculate QTD Sales by PRODUCT_GROUP\n",
        "    qtd_sales_license_seat_new = generate_qtd_sales_by_license(filtered_df, item)\n",
        "    qtd_sales_license_seat = pd.concat([qtd_sales_license_seat, qtd_sales_license_seat_new], axis=0)\n",
        "    #Plot QTD sales by license\n",
        "    plot_qtd_sales_license(qtd_sales_license_seat_new, DIRECTORY, item,  False)\n",
        "\n",
        "\n",
        "    #==========  Calculate ALL: Sales by Region & Panregion =========#\n",
        "    #Calculate Sales by Region and Quarter\n",
        "    sales_by_region_and_q_new = calculate_sales_by_region_and_quarter(filtered_df, item, 'QTD_Encoding')\n",
        "    sales_by_region_and_q = pd.concat([sales_by_region_and_q, sales_by_region_and_q_new], axis=0)\n",
        "    #Plot Sales by Region & Quarter\n",
        "    plot_sales_by_region(sales_by_region_and_q_new,item, DIRECTORY, False, 'Region', 'QTD_Encoding')\n",
        "\n",
        "\n",
        "    #Calculate Sales by Region and Year\n",
        "    sales_by_region_and_y_new = calculate_sales_by_region_and_quarter(filtered_df, item, 'YTD_Encoding')\n",
        "    sales_by_region_and_y = pd.concat([sales_by_region_and_y, sales_by_region_and_y_new], axis=0)\n",
        "    #Plot Sales by Region & Quarter\n",
        "    plot_sales_by_region(sales_by_region_and_q_new,item, DIRECTORY, False, 'Region', 'QTD_Encoding')\n",
        "\n",
        "\n",
        "    #Calculate Sales by Region and License\n",
        "    sales_by_region_and_lic_new = calculate_sales_by_region_and_lic(filtered_df, item)\n",
        "    sales_by_region_and_lic = pd.concat([sales_by_region_and_lic, sales_by_region_and_lic_new], axis=0)\n",
        "\n",
        "\n",
        "    #Plot Sales by Region & Quarter\n",
        "    plot_sales_by_region(sales_by_region_and_lic_new, item, DIRECTORY, False, 'Region', 'EID_GROUP')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0arWvhbCOLpq"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t1VlEeZaplk"
      },
      "outputs": [],
      "source": [
        "plot_MAT(df_MAT, DIRECTORY, '', True, 0, 'viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA-SFo96x9Af"
      },
      "outputs": [],
      "source": [
        "if productIdx == 0:\n",
        "  plot_MAT(df_MAT_group, DIRECTORY, ' - Product Group', True, 0,'tab10')\n",
        "\n",
        "print('')\n",
        "plot_MAT(df_MAT_region, DIRECTORY, ' - Regions' ,True, 0, 'tab20')\n",
        "\n",
        "print('')\n",
        "plot_MAT(df_MAT_panregion, DIRECTORY, ' - Panregions', True, 0, 'tab20')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiwRIks_OXbE"
      },
      "outputs": [],
      "source": [
        "plot_q_sales_trend(q_report_df, DIRECTORY, PRODUCT_GROUP, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFQvuN1ug3bu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhJho7PDYniq"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_1, PRODUCT_GROUP, DIRECTORY, True, 'Region', 'QTD_Encoding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5AfpZCJdtak"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_1, PRODUCT_GROUP, DIRECTORY, True, 'Panregion', 'QTD_Encoding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyiiZwxG2asJ"
      },
      "outputs": [],
      "source": [
        "plot_qtd_sales_license(qtd_sales_license_seat, DIRECTORY, PRODUCT_GROUP,  True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlyBT8cWmDY2"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_2, PRODUCT_GROUP, DIRECTORY, True, 'Region', 'EID_GROUP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptENpTiYaSUE"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_2, PRODUCT_GROUP, DIRECTORY, True, 'Panregion', 'EID_GROUP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aifSCMEnuosH"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_3, PRODUCT_GROUP, DIRECTORY, True, 'Region', 'YTD_Encoding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxYHoNW3ieyZ"
      },
      "outputs": [],
      "source": [
        "plot_sales_by_region(temp_data_3, PRODUCT_GROUP, DIRECTORY, True, 'Panregion', 'YTD_Encoding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqz2NoSXh6UQ"
      },
      "outputs": [],
      "source": [
        "plot_qtd_sales_region(temp_data_1, PRODUCT_GROUP, DIRECTORY,  'Region', True, 'tab20', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZw-knNGxZOk"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    plot_qtd_sales_region(temp_data_1, PRODUCT_GROUP, DIRECTORY, 'Panregion', True, 'tab20', False)\n",
        "except:\n",
        "    pass  # Skip to the next command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OTPLth6MDt8"
      },
      "source": [
        "## Wite to Excel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTV15AOEOLCG"
      },
      "source": [
        "Reshape data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbkBRxbIxVsm"
      },
      "outputs": [],
      "source": [
        "#reshape MAT data\n",
        "excel_MAT_WW = reshape_excel_plot_MAT(df_MAT)\n",
        "excel_MAT_byGroup = reshape_excel_plot_MAT(df_MAT_group)\n",
        "\n",
        "excel_MAT_byRegion = reshape_excel_plot_MAT(df_MAT_region)\n",
        "excel_MAT_byPanregion = reshape_excel_plot_MAT(df_MAT_panregion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWYf0cXVWMfU"
      },
      "outputs": [],
      "source": [
        "#Calculate growth for WW and by Group\n",
        "try:\n",
        "    growth_excel_MAT_WW = calculate_growth(excel_MAT_WW)\n",
        "    growth_excel_MAT_byGroup = calculate_growth(excel_MAT_byGroup)\n",
        "except IndexError:\n",
        "    growth_excel_MAT_WW = pd.DataFrame() #empty\n",
        "    growth_excel_MAT_byGroup = pd.DataFrame() #empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1atJ2l0CWvq"
      },
      "outputs": [],
      "source": [
        "#reshape quarterly short term sales trend\n",
        "excel_q_report_df = q_report_df.set_index('Product')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNG3AUX0Nq0t"
      },
      "outputs": [],
      "source": [
        "#reshape QTD sales&seat by licese\n",
        "excel_qtd_sales_license_seat = qtd_sales_license_seat.set_index('Product')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyPhsrs-4eFn"
      },
      "outputs": [],
      "source": [
        "#reshape QTD sakes by license\n",
        "excel_qtd_sales_license = qtd_sales_license_seat.loc[qtd_sales_license_seat['Unit'] != 'Seat (Qty)'] #drop \"Seat(Qty)\"\n",
        "excel_qtd_sales_license = excel_qtd_sales_license.drop(columns = ['Unit']) #drop \"Unit\"\n",
        "excel_qtd_sales_license.set_index('Product', inplace = True) #set roduct as index\n",
        "\n",
        "#calculate percetage per product\n",
        "excel_qtd_sales_license_pct = excel_qtd_sales_license.iloc[:, 0:].apply(lambda x: x/x.sum(), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj3N81VC2jw-"
      },
      "outputs": [],
      "source": [
        "#reshpa sales by region\n",
        "excel_by_region_reshaped = reshape_sales_by_region(sales_by_region_and_lic)\n",
        "excel_by_region_reshaped_pct = excel_by_region_reshaped.apply(lambda x: x/x.sum() if x.sum() != 0 else 0, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z3scQChQJks"
      },
      "source": [
        "Growth from excel reshapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPi6M89hORFj"
      },
      "source": [
        "Write to Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAMaZi-ojsJu"
      },
      "outputs": [],
      "source": [
        "with pd.ExcelWriter(DIRECTORY + '/_' + PRODUCT_GROUP + '_Excel_Report.xlsx', engine='xlsxwriter') as writer:\n",
        "  # Write each dataframe to one ksheet.\n",
        "  excel_MAT_WW.to_excel(writer, sheet_name='wwMAT')\n",
        "  excel_MAT_byGroup.to_excel(writer, sheet_name='groupMAT')\n",
        "  excel_MAT_byRegion.to_excel(writer, sheet_name='regMAT')\n",
        "  excel_MAT_byPanregion.to_excel(writer, sheet_name='panregMAT')\n",
        "\n",
        "  growth_excel_MAT_WW.to_excel(writer, sheet_name='wwMAT_growth')\n",
        "  growth_excel_MAT_byGroup.to_excel(writer, sheet_name='groupMAT_growth')\n",
        "\n",
        "  excel_q_report_df.to_excel(writer, sheet_name='trends_Q_Y')\n",
        "  excel_qtd_sales_license_seat.to_excel(writer, sheet_name='seatLicQTD')\n",
        "  excel_qtd_sales_license.to_excel(writer, sheet_name='licQTD')\n",
        "  excel_qtd_sales_license_pct.to_excel(writer, sheet_name='licPctQTD')\n",
        "  excel_by_region_reshaped.to_excel(writer, sheet_name='regQTD')\n",
        "  excel_by_region_reshaped_pct.to_excel(writer, sheet_name='regPctQTD')\n",
        "  sales_by_region_and_lic.to_excel(writer, sheet_name='regLicQTD')\n",
        "\n",
        "  sales_by_region_and_q.to_excel(writer, sheet_name='salesRegQ')\n",
        "  sales_by_region_and_y.to_excel(writer, sheet_name='salesRegY')\n",
        "  sales_trend_q_y_region_all.to_excel(writer, sheet_name='trendsReg_Q_Y')\n",
        "  sales_trend_q_y_panregion_all.to_excel(writer, sheet_name='trendsPanreg_Q_Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leeOm-PRfK9Q"
      },
      "source": [
        "## File Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g7ycuE7dMYU"
      },
      "outputs": [],
      "source": [
        "#Zip all reports\n",
        "#Run after generating repots for all\n",
        "TO_ZIP = False\n",
        "if TO_ZIP == True:\n",
        "  !zip -r '/content/QBR_REPORTS/QBR_Reports_CD.zip' '/content/QBR_REPORTS'\n",
        "  print('The zip file is successfully created!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFx1Q03Re1_s"
      },
      "outputs": [],
      "source": [
        "#============== WARNING: Delete All  ================#\n",
        "#-------- Deletes Reports Folder --------#\n",
        "DELETE_ALL = False\n",
        "if DELETE_ALL is True:\n",
        "  #============== WARNING: Delete All ================#\n",
        "  DELETE_ALL = input(\"Are you sure you want to delete all? 'y' to confirm: \")\n",
        "  if DELETE_ALL.lower() == 'y':\n",
        "      print('DELETED:', DIRECTORY)\n",
        "      shutil.rmtree('/content/QBR_REPORTS', ignore_errors=True)\n",
        "  else:\n",
        "      print(\"Deletion cancelled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhF5wWcqglCT"
      },
      "source": [
        "Report Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAvG5BN2XOpF"
      },
      "outputs": [],
      "source": [
        "#Reporting message\n",
        "print(f'Reports generated for Product Group {productIdx} \\n---------------------------------------')\n",
        "print('All: '+ PRODUCT_GROUP)\n",
        "print(''.join(\"{0}\\n\".format(x) for x in group_dct.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYjBKqBsTmJs"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript\n",
        "\n",
        "def display_notification(message):\n",
        "    js_code = f\"alert('{message}');\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "# Call the function to display the notification\n",
        "display_notification(\"All Done: The code has run to completion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy_MoCUZsNG0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVLwogE3vWINYSH+sHu4mP"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}